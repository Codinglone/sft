{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCs7P9JTMlzV"
   },
   "source": [
    "##### Copyright 2021 The TensorFlow Hub Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:56:57.191685Z",
     "iopub.status.busy": "2023-05-12T11:56:57.191443Z",
     "iopub.status.idle": "2023-05-12T11:56:57.195258Z",
     "shell.execute_reply": "2023-05-12T11:56:57.194737Z"
    },
    "id": "Jqn-HYw-Mkea"
   },
   "outputs": [],
   "source": [
    "#@title Copyright 2021 The TensorFlow Hub Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stRetE8gMlmZ"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/wav2vec2_saved_model_finetuning\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/wav2vec2_saved_model_finetuning.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/wav2vec2_saved_model_finetuning.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/wav2vec2_saved_model_finetuning.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/vasudevgupta7/wav2vec2/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndG8MjmJeicp"
   },
   "source": [
    "# Fine-tuning Wav2Vec2 with an LM head\n",
    "\n",
    "In this notebook, we will load the pre-trained wav2vec2 model from [TFHub](https://tfhub.dev) and will fine-tune it on [LibriSpeech dataset](https://huggingface.co/datasets/librispeech_asr) by appending Language Modeling head (LM) over the top of our pre-trained model. The underlying task is to build a model for **Automatic Speech Recognition** i.e. given some speech, the model should be able to transcribe it into text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWk8nL6Ui-_0"
   },
   "source": [
    "## Setting Up\n",
    "\n",
    "Before running this notebook, please ensure that you are on GPU runtime (`Runtime` > `Change runtime type` > `GPU`). The following cell will install [`gsoc-wav2vec2`](https://github.com/vasudevgupta7/gsoc-wav2vec2) package & its dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:56:57.198424Z",
     "iopub.status.busy": "2023-05-12T11:56:57.197918Z",
     "iopub.status.idle": "2023-05-12T11:57:13.025749Z",
     "shell.execute_reply": "2023-05-12T11:57:13.024775Z"
    },
    "id": "seqTlMyeZvM4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 100%\r",
      "\r",
      "Reading package lists... Done\r",
      "\r\n",
      "\r",
      "Building dependency tree... 0%\r",
      "\r",
      "Building dependency tree... 0%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Building dependency tree... 50%\r",
      "\r",
      "Building dependency tree... 50%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Building dependency tree       \r",
      "\r\n",
      "\r",
      "Reading state information... 0%\r",
      "\r",
      "Reading state information... 0%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Reading state information... Done\r",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages were automatically installed and are no longer required:\r\n",
      "  libatasmart4 libblockdev-fs2 libblockdev-loop2 libblockdev-part-err2\r\n",
      "  libblockdev-part2 libblockdev-swap2 libblockdev-utils2 libblockdev2\r\n",
      "  libparted-fs-resize0 libxmlb2\r\n",
      "Use 'sudo apt autoremove' to remove them.\r\n",
      "The following additional packages will be installed:\r\n",
      "  libflac-dev libogg-dev libvorbis-dev\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libflac-dev libogg-dev libsndfile1-dev libvorbis-dev\r\n",
      "0 upgraded, 4 newly installed, 0 to remove and 184 not upgraded.\r\n",
      "Need to get 908 kB of archives.\r\n",
      "After this operation, 4278 kB of additional disk space will be used.\r\n",
      "\r",
      "0% [Working]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "            \r",
      "Get:1 http://us-west1.gce.archive.ubuntu.com/ubuntu focal/main amd64 libogg-dev amd64 1.3.4-0ubuntu1 [161 kB]\r\n",
      "\r",
      "1% [1 libogg-dev 13.7 kB/161 kB 8%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                   \r",
      "19% [Working]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "             \r",
      "Get:2 http://us-west1.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 libflac-dev amd64 1.3.3-1ubuntu0.1 [151 kB]\r\n",
      "\r",
      "20% [2 libflac-dev 9460 B/151 kB 6%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                    \r",
      "37% [Waiting for headers]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                         \r",
      "Get:3 http://us-west1.gce.archive.ubuntu.com/ubuntu focal/main amd64 libvorbis-dev amd64 1.3.6-2ubuntu1 [316 kB]\r\n",
      "\r",
      "38% [3 libvorbis-dev 2420 B/316 kB 1%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                      \r",
      "70% [Waiting for headers]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                         \r",
      "Get:4 http://us-west1.gce.archive.ubuntu.com/ubuntu focal-updates/main amd64 libsndfile1-dev amd64 1.0.28-7ubuntu0.1 [280 kB]\r\n",
      "\r",
      "72% [4 libsndfile1-dev 22.1 kB/280 kB 8%]\r",
      "                                         \r",
      "100% [Working]\r",
      "              \r",
      "Fetched 908 kB in 1s (933 kB/s)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libogg-dev:amd64.\r\n",
      "(Reading database ... \r",
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r",
      "(Reading database ... 65%\r",
      "(Reading database ... 70%\r",
      "(Reading database ... 75%\r",
      "(Reading database ... 80%\r",
      "(Reading database ... 85%\r",
      "(Reading database ... 90%\r",
      "(Reading database ... 95%\r",
      "(Reading database ... 100%\r",
      "(Reading database ... 139938 files and directories currently installed.)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../libogg-dev_1.3.4-0ubuntu1_amd64.deb ...\r\n",
      "Unpacking libogg-dev:amd64 (1.3.4-0ubuntu1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libflac-dev:amd64.\r\n",
      "Preparing to unpack .../libflac-dev_1.3.3-1ubuntu0.1_amd64.deb ...\r\n",
      "Unpacking libflac-dev:amd64 (1.3.3-1ubuntu0.1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libvorbis-dev:amd64.\r\n",
      "Preparing to unpack .../libvorbis-dev_1.3.6-2ubuntu1_amd64.deb ...\r\n",
      "Unpacking libvorbis-dev:amd64 (1.3.6-2ubuntu1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libsndfile1-dev.\r\n",
      "Preparing to unpack .../libsndfile1-dev_1.0.28-7ubuntu0.1_amd64.deb ...\r\n",
      "Unpacking libsndfile1-dev (1.0.28-7ubuntu0.1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up libogg-dev:amd64 (1.3.4-0ubuntu1) ...\r\n",
      "Setting up libvorbis-dev:amd64 (1.3.6-2ubuntu1) ...\r\n",
      "Setting up libflac-dev:amd64 (1.3.3-1ubuntu0.1) ...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up libsndfile1-dev (1.0.28-7ubuntu0.1) ...\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q git+https://github.com/vasudevgupta7/gsoc-wav2vec2@main\n",
    "!sudo apt-get install -y libsndfile1-dev\n",
    "!pip3 install -q SoundFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvuJL8-f0zn5"
   },
   "source": [
    "## Model setup using `TFHub`\n",
    "\n",
    "We will start by importing some libraries/modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:13.030322Z",
     "iopub.status.busy": "2023-05-12T11:57:13.029763Z",
     "iopub.status.idle": "2023-05-12T11:57:15.467932Z",
     "shell.execute_reply": "2023-05-12T11:57:15.467245Z"
    },
    "id": "M3_fgx4eZvM7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.13.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from wav2vec2 import Wav2Vec2Config\n",
    "\n",
    "config = Wav2Vec2Config()\n",
    "\n",
    "print(\"TF version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0rVUxyWsS5f"
   },
   "source": [
    "First, we will download our model from TFHub & will wrap our model signature with [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) to be able to use this model like any other Keras layer. Fortunately, `hub.KerasLayer` can do both in just 1 line.\n",
    "\n",
    "**Note:** When loading model with `hub.KerasLayer`, model becomes a bit opaque but sometimes we need finer controls over the model, then we can load the model with `tf.keras.models.load_model(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:15.471384Z",
     "iopub.status.busy": "2023-05-12T11:57:15.471016Z",
     "iopub.status.idle": "2023-05-12T11:57:29.317813Z",
     "shell.execute_reply": "2023-05-12T11:57:29.317051Z"
    },
    "id": "NO6QRC7KZvM9"
   },
   "outputs": [],
   "source": [
    "pretrained_layer = hub.KerasLayer(\"https://tfhub.dev/vasudevgupta7/wav2vec2/1\", trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCputyVBv2e9"
   },
   "source": [
    "You can refer to this [script](https://github.com/vasudevgupta7/gsoc-wav2vec2/blob/main/src/export2hub.py) in case you are interested in the model exporting script. Object `pretrained_layer` is the freezed version of [`Wav2Vec2Model`](https://github.com/vasudevgupta7/gsoc-wav2vec2/blob/main/src/wav2vec2/modeling.py). These pre-trained weights were converted from HuggingFace PyTorch [pre-trained weights](https://huggingface.co/facebook/wav2vec2-base) using [this script](https://github.com/vasudevgupta7/gsoc-wav2vec2/blob/main/src/convert_torch_to_tf.py).\n",
    "\n",
    "Originally, wav2vec2 was pre-trained with a masked language modelling approach with the objective to identify the true quantized latent speech representation for a masked time step. You can read more about the training objective in the paper- [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SseDnCr7hyhC"
   },
   "source": [
    "Now, we will be defining a few constants and hyper-parameters which will be useful in the next few cells. `AUDIO_MAXLEN` is intentionally set to `246000` as the model signature only accepts static sequence length of `246000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:29.322184Z",
     "iopub.status.busy": "2023-05-12T11:57:29.321598Z",
     "iopub.status.idle": "2023-05-12T11:57:29.325169Z",
     "shell.execute_reply": "2023-05-12T11:57:29.324567Z"
    },
    "id": "eiILuMBERxlO"
   },
   "outputs": [],
   "source": [
    "AUDIO_MAXLEN = 246000\n",
    "LABEL_MAXLEN = 256\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1V4gTgGLgXvO"
   },
   "source": [
    "In the following cell, we will wrap `pretrained_layer` & a dense layer (LM head) with the [Keras's Functional API](https://www.tensorflow.org/guide/keras/functional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:29.328376Z",
     "iopub.status.busy": "2023-05-12T11:57:29.327784Z",
     "iopub.status.idle": "2023-05-12T11:57:29.903855Z",
     "shell.execute_reply": "2023-05-12T11:57:29.903075Z"
    },
    "id": "a3CUN1KEB10Q"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(AUDIO_MAXLEN,))\n",
    "hidden_states = pretrained_layer(inputs)\n",
    "outputs = tf.keras.layers.Dense(config.vocab_size)(hidden_states)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zDXuoMXhDMo"
   },
   "source": [
    "The dense layer (defined above) is having an output dimension of `vocab_size` as we want to predict probabilities of each token in the vocabulary at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPp18ZHRtnq-"
   },
   "source": [
    "## Setting up training state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATQy1ZK3vFr7"
   },
   "source": [
    "In TensorFlow, model weights are built only when `model.call` or `model.build` is called for the first time, so the following cell will build the model weights for us. Further, we will be running `model.summary()` to check the total number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:29.908265Z",
     "iopub.status.busy": "2023-05-12T11:57:29.907617Z",
     "iopub.status.idle": "2023-05-12T11:57:32.406039Z",
     "shell.execute_reply": "2023-05-12T11:57:32.405321Z"
    },
    "id": "ZgL5wyaXZvM-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_1 (InputLayer)        [(None, 246000)]          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " keras_layer (KerasLayer)    (None, 768, 768)          94371712  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense (Dense)               (None, 768, 32)           24608     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 94396320 (360.09 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 94396320 (360.09 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0 (0.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model(tf.random.uniform(shape=(BATCH_SIZE, AUDIO_MAXLEN)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQxxA4Fevp7m"
   },
   "source": [
    "Now, we need to define the `loss_fn` and optimizer to be able to train the model. The following cell will do that for us. We will be using the `Adam` optimizer for simplicity. `CTCLoss` is a common loss type that is used for tasks (like `ASR`) where input sub-parts can't be easily aligned with output sub-parts. You can read more about CTC-loss from this amazing [blog post](https://distill.pub/2017/ctc/).\n",
    "\n",
    "\n",
    "`CTCLoss` (from [`gsoc-wav2vec2`](https://github.com/vasudevgupta7/gsoc-wav2vec2) package) accepts 3 arguments: `config`, `model_input_shape` & `division_factor`. If `division_factor=1`, then loss will simply get summed, so pass `division_factor` accordingly to get mean over batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:32.409282Z",
     "iopub.status.busy": "2023-05-12T11:57:32.409016Z",
     "iopub.status.idle": "2023-05-12T11:57:32.415597Z",
     "shell.execute_reply": "2023-05-12T11:57:32.414933Z"
    },
    "id": "glDepVEHZvM_"
   },
   "outputs": [],
   "source": [
    "from wav2vec2 import CTCLoss\n",
    "\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "loss_fn = CTCLoss(config, (BATCH_SIZE, AUDIO_MAXLEN), division_factor=BATCH_SIZE)\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mvTuOXpwsQe"
   },
   "source": [
    "## Loading & Pre-processing data\n",
    "\n",
    "Let's now download the LibriSpeech dataset from the [official website](http://www.openslr.org/12) and set it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:32.418637Z",
     "iopub.status.busy": "2023-05-12T11:57:32.418139Z",
     "iopub.status.idle": "2023-05-12T11:57:52.603522Z",
     "shell.execute_reply": "2023-05-12T11:57:52.602299Z"
    },
    "id": "I4kIEC77cBCM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-12 11:57:32--  https://www.openslr.org/resources/12/dev-clean.tar.gz\r\n",
      "Resolving www.openslr.org (www.openslr.org)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.101.158.64\r\n",
      "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 Found\r\n",
      "Location: http://us.openslr.org/resources/12/dev-clean.tar.gz [following]\r\n",
      "--2023-05-12 11:57:33--  http://us.openslr.org/resources/12/dev-clean.tar.gz\r\n",
      "Resolving us.openslr.org (us.openslr.org)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.101.158.64\r\n",
      "Connecting to us.openslr.org (us.openslr.org)|46.101.158.64|:80... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected.\r\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\r\n",
      "Length: 337926286 (322M) [application/x-gzip]\r\n",
      "Saving to: ‘./data/train/dev-clean.tar.gz’\r\n",
      "\r\n",
      "\r",
      "dev-clean.tar.gz      0%[                    ]       0  --.-KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz      0%[                    ]  48.95K   175KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz      0%[                    ] 213.95K   383KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz      0%[                    ] 873.95K  1.02MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz      1%[                    ]   3.43M  3.07MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz      2%[                    ]   8.77M  6.28MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz      4%[                    ]  14.32M  8.54MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz      6%[>                   ]  20.20M  10.3MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz      7%[>                   ]  24.94M  11.6MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz      8%[>                   ]  28.84M  12.1MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     10%[=>                  ]  32.98M  12.8MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     11%[=>                  ]  37.35M  13.4MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     12%[=>                  ]  41.28M  13.8MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     14%[=>                  ]  46.05M  14.3MB/s    eta 19s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     15%[==>                 ]  50.04M  14.6MB/s    eta 19s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     16%[==>                 ]  54.45M  15.0MB/s    eta 19s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     18%[==>                 ]  58.41M  16.4MB/s    eta 19s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     19%[==>                 ]  63.24M  18.0MB/s    eta 19s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     20%[===>                ]  67.13M  19.9MB/s    eta 16s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     22%[===>                ]  71.89M  20.1MB/s    eta 16s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     23%[===>                ]  75.81M  19.9MB/s    eta 16s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     24%[===>                ]  80.43M  20.5MB/s    eta 16s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     26%[====>               ]  84.39M  20.3MB/s    eta 16s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     27%[====>               ]  87.82M  20.1MB/s    eta 14s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     28%[====>               ]  93.22M  20.4MB/s    eta 14s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     29%[====>               ]  96.30M  20.1MB/s    eta 14s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     31%[=====>              ] 101.67M  20.1MB/s    eta 14s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     32%[=====>              ] 105.00M  20.1MB/s    eta 14s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     34%[=====>              ] 109.61M  20.2MB/s    eta 12s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     35%[======>             ] 113.52M  20.2MB/s    eta 12s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     36%[======>             ] 117.83M  20.0MB/s    eta 12s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     37%[======>             ] 122.06M  20.0MB/s    eta 12s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     39%[======>             ] 126.25M  20.2MB/s    eta 12s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     40%[=======>            ] 130.55M  20.1MB/s    eta 11s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     41%[=======>            ] 135.01M  20.3MB/s    eta 11s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     43%[=======>            ] 138.81M  19.9MB/s    eta 11s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     44%[=======>            ] 144.37M  20.3MB/s    eta 11s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     45%[========>           ] 147.61M  19.8MB/s    eta 11s    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     47%[========>           ] 153.48M  20.2MB/s    eta 9s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     49%[========>           ] 158.23M  20.5MB/s    eta 9s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     50%[=========>          ] 162.11M  20.2MB/s    eta 9s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     51%[=========>          ] 166.63M  20.1MB/s    eta 9s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     53%[=========>          ] 170.97M  20.0MB/s    eta 9s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     54%[=========>          ] 176.27M  20.6MB/s    eta 8s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     55%[==========>         ] 179.73M  20.3MB/s    eta 8s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     57%[==========>         ] 184.60M  20.5MB/s    eta 8s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     58%[==========>         ] 188.42M  20.3MB/s    eta 8s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     59%[==========>         ] 192.96M  20.3MB/s    eta 8s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     61%[===========>        ] 197.15M  20.2MB/s    eta 7s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     62%[===========>        ] 201.44M  20.2MB/s    eta 7s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     63%[===========>        ] 205.65M  20.5MB/s    eta 7s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     65%[============>       ] 209.90M  20.6MB/s    eta 7s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     66%[============>       ] 214.12M  20.5MB/s    eta 7s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     67%[============>       ] 218.61M  20.3MB/s    eta 6s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     69%[============>       ] 222.72M  20.2MB/s    eta 6s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     70%[=============>      ] 227.16M  20.6MB/s    eta 6s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     71%[=============>      ] 231.61M  20.5MB/s    eta 6s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     73%[=============>      ] 235.60M  20.5MB/s    eta 6s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     74%[=============>      ] 240.03M  20.4MB/s    eta 4s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     75%[==============>     ] 244.32M  20.3MB/s    eta 4s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     77%[==============>     ] 248.42M  20.4MB/s    eta 4s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     78%[==============>     ] 252.75M  20.4MB/s    eta 4s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     79%[==============>     ] 257.10M  20.4MB/s    eta 4s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     81%[===============>    ] 261.41M  20.5MB/s    eta 3s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     82%[===============>    ] 265.85M  20.3MB/s    eta 3s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     83%[===============>    ] 269.65M  20.1MB/s    eta 3s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     85%[================>   ] 274.58M  20.5MB/s    eta 3s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     86%[================>   ] 278.34M  20.3MB/s    eta 3s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     87%[================>   ] 283.07M  20.5MB/s    eta 2s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     89%[================>   ] 287.09M  20.5MB/s    eta 2s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     90%[=================>  ] 291.09M  20.3MB/s    eta 2s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     91%[=================>  ] 294.99M  20.4MB/s    eta 2s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     92%[=================>  ] 299.08M  20.4MB/s    eta 2s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     94%[=================>  ] 303.52M  20.4MB/s    eta 1s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     95%[==================> ] 307.64M  20.4MB/s    eta 1s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     96%[==================> ] 312.29M  20.4MB/s    eta 1s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     98%[==================> ] 315.94M  20.3MB/s    eta 1s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz     99%[==================> ] 320.96M  20.3MB/s    eta 1s     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "dev-clean.tar.gz    100%[===================>] 322.27M  20.3MB/s    in 17s     \r\n",
      "\r\n",
      "2023-05-12 11:57:50 (19.2 MB/s) - ‘./data/train/dev-clean.tar.gz’ saved [337926286/337926286]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.openslr.org/resources/12/dev-clean.tar.gz -P ./data/train/\n",
    "!tar -xf ./data/train/dev-clean.tar.gz -C ./data/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsQpmpn6jrMI"
   },
   "source": [
    "**Note:** We are using `dev-clean` configuration as this notebook is just for demonstration purposes, so we need a small amount of data. Complete training data can be easily downloaded from [LibriSpeech website](http://www.openslr.org/12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:52.608035Z",
     "iopub.status.busy": "2023-05-12T11:57:52.607744Z",
     "iopub.status.idle": "2023-05-12T11:57:52.801881Z",
     "shell.execute_reply": "2023-05-12T11:57:52.801076Z"
    },
    "id": "ynxAjtGHGFpM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mLibriSpeech\u001b[0m/  dev-clean.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls ./data/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBMiORo0xJD0"
   },
   "source": [
    "Our dataset lies in the LibriSpeech directory. Let's explore these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:52.805452Z",
     "iopub.status.busy": "2023-05-12T11:57:52.805208Z",
     "iopub.status.idle": "2023-05-12T11:57:52.810487Z",
     "shell.execute_reply": "2023-05-12T11:57:52.809831Z"
    },
    "id": "jkIu_Wt4ZvNA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription files: ['2428-83705.trans.txt'] \n",
      "Sound files: ['2428-83705-0008.flac', '2428-83705-0031.flac', '2428-83705-0035.flac', '2428-83705-0012.flac', '2428-83705-0038.flac', '2428-83705-0033.flac', '2428-83705-0000.flac', '2428-83705-0041.flac', '2428-83705-0026.flac', '2428-83705-0002.flac', '2428-83705-0037.flac', '2428-83705-0005.flac', '2428-83705-0015.flac', '2428-83705-0003.flac', '2428-83705-0023.flac', '2428-83705-0021.flac', '2428-83705-0034.flac', '2428-83705-0028.flac', '2428-83705-0040.flac', '2428-83705-0043.flac', '2428-83705-0010.flac', '2428-83705-0018.flac', '2428-83705-0042.flac', '2428-83705-0032.flac', '2428-83705-0039.flac', '2428-83705-0017.flac', '2428-83705-0007.flac', '2428-83705-0019.flac', '2428-83705-0022.flac', '2428-83705-0036.flac', '2428-83705-0011.flac', '2428-83705-0029.flac', '2428-83705-0001.flac', '2428-83705-0027.flac', '2428-83705-0014.flac', '2428-83705-0009.flac', '2428-83705-0024.flac', '2428-83705-0020.flac', '2428-83705-0025.flac', '2428-83705-0030.flac', '2428-83705-0016.flac', '2428-83705-0013.flac', '2428-83705-0004.flac', '2428-83705-0006.flac']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data/train/LibriSpeech/dev-clean/2428/83705/\"\n",
    "all_files = os.listdir(data_dir)\n",
    "\n",
    "flac_files = [f for f in all_files if f.endswith(\".flac\")]\n",
    "txt_files = [f for f in all_files if f.endswith(\".txt\")]\n",
    "\n",
    "print(\"Transcription files:\", txt_files, \"\\nSound files:\", flac_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEObi_Apk3ZD"
   },
   "source": [
    "Alright, so each sub-directory has many `.flac` files and a `.txt` file. The `.txt` file contains text transcriptions for all the speech samples (i.e. `.flac` files) present in that sub-directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYW6WKJflO2e"
   },
   "source": [
    "We can load this text data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:52.813336Z",
     "iopub.status.busy": "2023-05-12T11:57:52.813125Z",
     "iopub.status.idle": "2023-05-12T11:57:52.817075Z",
     "shell.execute_reply": "2023-05-12T11:57:52.816513Z"
    },
    "id": "cEBKxQblHPwq"
   },
   "outputs": [],
   "source": [
    "def read_txt_file(f):\n",
    "  with open(f, \"r\") as f:\n",
    "    samples = f.read().split(\"\\n\")\n",
    "    samples = {s.split()[0]: \" \".join(s.split()[1:]) for s in samples if len(s.split()) > 2}\n",
    "  return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ldkf_ceb0_YW"
   },
   "source": [
    "Similarly, we will define a function for loading a speech sample from a `.flac` file.\n",
    "\n",
    "`REQUIRED_SAMPLE_RATE` is set to `16000` as wav2vec2 was pre-trained with `16K` frequency and it's recommended to fine-tune it without any major change in data distribution due to frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:52.819938Z",
     "iopub.status.busy": "2023-05-12T11:57:52.819729Z",
     "iopub.status.idle": "2023-05-12T11:57:52.827872Z",
     "shell.execute_reply": "2023-05-12T11:57:52.827264Z"
    },
    "id": "YOJ3OzPsTyXv"
   },
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "REQUIRED_SAMPLE_RATE = 16000\n",
    "\n",
    "def read_flac_file(file_path):\n",
    "  with open(file_path, \"rb\") as f:\n",
    "      audio, sample_rate = sf.read(f)\n",
    "  if sample_rate != REQUIRED_SAMPLE_RATE:\n",
    "      raise ValueError(\n",
    "          f\"sample rate (={sample_rate}) of your files must be {REQUIRED_SAMPLE_RATE}\"\n",
    "      )\n",
    "  file_id = os.path.split(file_path)[-1][:-len(\".flac\")]\n",
    "  return {file_id: audio}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sxDN8P4nWkW"
   },
   "source": [
    "Now, we will pick some random samples & will try to visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:52.830748Z",
     "iopub.status.busy": "2023-05-12T11:57:52.830541Z",
     "iopub.status.idle": "2023-05-12T11:57:52.841228Z",
     "shell.execute_reply": "2023-05-12T11:57:52.840679Z"
    },
    "id": "HI5J-2Dfm_wT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Transcription: SOMEONE SNIGGERED \n",
      "Audio:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/flac;base64,ZkxhQwAAACIQABAAAARrABX4A+gA8AAAeoAHoSxBqIPNWvhElo+8loSDAwAAEgAAAAAAAAAAAAAAAAAAAAAQAAQAACggAAAAcmVmZXJlbmNlIGxpYkZMQUMgMS4yLjEgMjAwNzA5MTcAAAAAgQAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//jFCABvEv/4AEhDLitI8mkmVCuP5Fi8pEu3jiiIauExSMzQyCEhZHammoFG9KaiXTtETroyLMITO1TSv5E5TveLZEiat4rqWLaDzLwiJElwRADFBGFAtmj2IhEvZohROypGY4IKQjGZCLC6skSNumUvItGk75y6ZeRbMSVSAh9nFbVrBSIMmaUQVyTJ6x5AiJOZyEE+EiYJ5TRlq9CF3PbE6SJTWOXES3ou6f1/Fm9EY0MwhS049BOkY0LSvUI9EJeIkvT9rQsWn/MIKJDFmpI6IcvwlozlJEuKMJxqPJQipn5EGSiWSNFuKmbJvXUX+JJJKWnEzi4i3ZqEKZy8iTL5oI+FPouBEnpyhRTNG0uLgzOawhaZyXpTgmCLvsqJtjJB16FtTCRKRZqjIV6mibqE8sn4o+yOIsjVbREXP2PElUeZ4hEhTGNiSCITFGDVBKp6lKPyYiwhGop4yyEvRh2RfNMVkUFJq+LV+mlJKIx5erJTrMgjIQmW1IfkWgQuP/IoJwdtSZPkSKIZrkhFzDNDaxEJKUyJsFFEPRB++Wa0KLeMcSQQidcI70rU/rKEEheZvUFNWoUW8lRJ5OvItIJyebkEkZlNeVsZFeTaIn8UZr8WI0qiNEiILM3FpfjEIUSzYgRE4Y5trZCZBZJC9KadJSGlxSJmkIVGTYa0ETFOKZkzUksY1QwotQdvz4kSSSHjXDAoRFmeVItrMNmQRCybJCIJhHQVu0NyXypCUTJRkK0RN48USJyO6qoh4kJovYnOvm42lRIic2ikm+jQWLx0sEXFp8mzlCSLEZtcICWSvkskhHKFELzRJ9O1a/IKi0eoZBKiH0STf//XAqqkpQvNMd/2K6EhKSM5TEKEw9uKS08YpFVdYiJUcWgm0o2I6yHoJ1JvwgiJDPbMEhMbLbFZYLZGSchUJvRt7LJSRPREkjktCKJTGxMSYuPTZSVG98K5BZNLUWRbpKWkwjaU0RMtZwiy/M3dXC3qIgkViJLyHt6CqZhuhCTMmFxLRBTfnoRbPDSyFLcMRfkTYUbOFlG0TGJDZwmWIIhy7oUCckXTGS1BNEuSTC2xkk9vV/JoJliFlsSy6bWxbMkpp20EIpMWA6JQkE00DeWSJD+NJhXYkJENEkkIxkuI2THjYRKyTtZiBIgjG46KTTFRoJNpxeKjeWZRS95lIkjE3ldnQiMRJEli8rJqyDjZXfK2LZFQ4tI0RwxclKWzl8hWRBXEnlGceJRkTZE2hEtYfYpYV4hNFRiRCK8ZsiKJDNKXluEV1iZMTZDNS6fEixERYLkcBEiUGZv3AkzkOknwVpzkSrCJqzPLBFRj5KKIZkSSRPiJPaeURzopebqERVIULcd8T0+LVhZs4QoggKBhjrBBQmbK0KUYkra5J5ObLgieGkISEY23LiFImQ+RpCCK3zqCCEY2fRCHGDwxESEkz+KhFTw0rERnJQk50sWt8RJp8iJzfCRRPGG9kyReeSQiEibKZehrRlvg8QSzFK1qTRv/OVlG2JKJWiRIxRt5STTbJAmfHkiWsf2iJ5SMIWiz5E0AotzkSMwyESIp5uE8lt1k4EJJomyESel/TTakvniTdxhEk+TSiqT3xE3isJQLP1AnJ83mQro7JChJN5NfLUfCRyCaXKojk8lotTOTxEhDI4yBTIS+ndCmsXLsl43l3zOnJ6hn2CkinQIEKqoJbdiCjUx0Yi5WIh1CWhXM5QhYa2FwW0h56glFkZuIiCE6kXTdqiYLmDNEeIkWPJpKiRt8UgkPUbJBNzUUL/bKLFLR48SLlLQxIhF6egS+Y2tBKJ+91IRI3ySIWoGLUgQme66Rdm2kKyM9NIoTQzYyF6hGajIQkS8uhYiipoluGxPQlnuLKJmlFhP9tLESHeeSiExQ/ZEiR7dCxOZ3SEMKXZcxTXijdFxJf5G1CEbekmgrMT8iimshXotkSg5RIyEN5lk9zy7bhexBcoRLu8UhWT2ZGqlLU/WUb0VJkzlHpIwjIhSZySpLZkRQROa2oiSqP1LRjGQpClcyKSTEb64tO2Uojie0iRWZ9rV+yRQrFO0rdGicJ0flIomJf22SrzXwSEqfbySUMcKkK8elKW3TQhR2yfEIm/bCyISJPerCCSW3GKEjEzKiIe0yEVdHpBYkWE8A//jFCAFoEv/7AF1qgpmi7LGuSUykhs2IkJSMc4oUR7VL0ChRzMbxStOEkE0gl1jRCKXsPRUR4oiQQWyrxZadBD1DyWn9FMSkWrlDjUl3SfiFMj9ymK5RvYjFFGamiURWR6WRTucyS3yiYsRlGFxFepjKEVk40+BCCQ1JzXblELrt6J4plNUuN9JGeiVVqSEJMZLRiXrGZ3SFETHCiWSy1/6KCHm0KEKgxt6iJNUzYsj++U/BbtxJEuOIkhrInRq8SNcE2CRNpaFgkmCpn+wgSWn8hQ5HxLVcNip2Fy9rJpctE4lwjDGIUtMM6RBJ6iRAi5pmoTVp8USTQKnLEoiYz/QiTGOfIQI9+0TFEq2iUNX1qS1mZvXTdqykiWEWMlhWp5oUSUZ0kSkpkL8ToV30RYrxlIqxZoSooeQuFpRBzTSSNMzZohWc1lEs1ISReYudEtJUdwWRHk2ZAiiMH1CCLZG00KCQksaaoCSvOFKky/Pl8SzfxLlHHSSuJ2oieKamvhdmikGEFflJHIUa8lCWGEvoXKGydwv8WikUUFs/dmrmiTeiwkvqchlJplkrtqInoJybT1C3zfJQWLc04V2rsRLuy5KIqXb8RK5oSsJr13SEUx0rUEUubjkFKcU2WmKi3zJrZFHfonrcF9U5piEjQo0cLsJGpx64Sx59CWxXFqyVxMnCjIFulrKHY12K15pXKRXZ/IyynS1iUuRLS0u5KIpv4jWJ23l2kaSWtJJWTsLWLfNFJyXai3IW5DoipnWxJQss5SJb7E2LKe1yJNE01c9NYvi26ExJAsxsj6U95LUhfIVJJah6XJY4gykiNTZoiyT/KQQ1c9JhBZb2asIhSzZoWQrCNGvflaJpQm6VCoTLeWiE8Rv9ClrXo3kMjlcq7FpGi3DCKoU64iresiMtfTKK1Z8tqF1SvJBcmnpokRZdZErqGr1WTWYyViWZNeCSX5sugXMt08ixV3IRWuyWX+h8kvcJknEpLm2FCch2FJrLFkYpVIisyTvVejTi6KXrEa6kRZ1akLZLJip4kcJUfVELa7oV4shmXssudUpUiya9MU3Vla6v/RJvEDt0iK7d5CJ1mk4JSiNGSYpTNKySKqycXmWlrKEMp+rSLi3ry2TaMtrEaLLiiifI4taa5sQuLR2kSnjaxUZ1ci5S16p1KROUNIjEUpkvsp9aSSLMTmoU1ipOJ4nC00jTI1Tab4U7broo4qu0mgj2SiJcjSyWhLsqxFW8iO0q/SUidzrRFSLO1RcdjFLyM+ZcScsuEQ1o5TVyO0ZReUSNdV/QjKIyeplGUlZFkq8j0L/pFktXEmWSMu5SFLn0siNLZ12Tqjk9CPrtlQkwgeJqTK2vnF6XJJllSZRempK1qKK+amS1KWxE5KJic1I3qVEnZH1oa9RppRl9PUSR0LNSRLyVoGkVUvREYSp16haLTxNQvVq6SmWX5U4UTNgjS8uxHtRJGtpSSXNk1lUmqI8Ln5YRatVaJLgmzCSayQYmsUi/p+FMi90iHiSZJwX2kxNHLabkTEWuOC8LNNL1Q1bKZZpRZCpK2lEhksk2lxYksxXIkT2E7slzGkZLSi3krV7pWianlkqSbJeUl7SmJXIRzRKnuqstFB1m6F/YSLixoriRmlzER8SjEVk9MypF5OTebIh4mlzE0JlINXyj/5SSFdo1HCqlCD9SqBH2iaNc6knqq2K+SFu3xiBGLb8SSLk8plJFFatoVlR04iU6pCymjrRLTryWVXfESLcs0spyok9SXRa2yMquRElO1Oy9dZHLTJNJGQtytEnUxSaI/ySu06uJOUnkyUUn95PU18yaS1U7WltegZJu9RQUIi11XxXW75zQoUwtimlpxCmpIqVPU0nCmJ2RVpslyRsl2Rilq7XUrRNGTEylo4uS2KaR8tipkynSJwSGysXWTK+Jdi8k7IlFGVpFUddW9KGVtFukyzJEMVFPd6UuNJIuvssS3addka3xcLmRT8mUhRXNiJxcolLqWlFbVrzp//jFCAJhEgADGHklNTti4vSneRYSZ/oqiT01qyKXrdjIu4WR6+C9JrlwrpQtyMQy2F7EuE5LheKWysi7NkqylDulrI9ZalpyHpaiPSrWPp6qbFnJk4mcSaNRHlk7tV5NRMQuRZXCV2QvnFy1sRboormIRp7yNWhGjWheytcKqtO2wlVcE4qS9zSXpNollsUnlMRi0ZDI01lETJOibFsmqWS27MKaVobEorItvZMhUW661tboXlOa8RiymbXa8K1zSi/LxDtWtLojklSlOhZiWkWhoodF6RDSI06SYhdpqK16TK3thcTrJzyRaFWUVTqPFFMof4oI8mSpkCOmjVkISS0rSL5bfIkI8sdiZE2drCJbLST5u682ytF4jnI35p0YXPUT4a5juUmHINWPo3IE9hvFV6NjkpKIJQILEkOWgy/v63/GOF+ik1jGVsRSZrzHDzQGJg7U19viKeLvME9DFB3Q1szAksZNlnDJ9Y1R+vijZ/2oKNM31m8MoIQvY0qV0Hlw2vjRPHhrDgpnKK2dCJb5976QUP0ConieSLfPkczBunhSRp8PMv8p7NiWciNWY4cHaxAr8ZCu1TqJX9Tfj3w+oVolOlUN6mUwoFNAqxJdOdUmOYgoLaDK817MgsF4ZhkbAh0DQIRKCBQEsXXkHb9EmWtBgxJFKZarPu5QjqchK65qlpzYOiz/bLbGxSvuZSIaOfL5LjlarNt5EDAUaDVNK7EKDCLbAXiiWzwwH2klb2kS18hHwIJdD4mBt6Gz+hsEefKjz58mvewoCDWlxUbH1i5PnHW5m4agU+J8YD/QcEOpjgLgr2xmqCXwHgQRDBwEN+GAeDBwqa74o4iWwoip8xBWZiszy9bVEQDBpsyss4/u55Dcly9fDmJvPMC1NF+VzLrGZ6sMyP3jtFcQvEXhIlGVj0LF/iyf2KdRkxMMvYmK0gEyIM0H0KVBjKiCdSC8XJqlMrnrtrTaY8x7VMZ/ZDxlP6l36TmVP9CrX01Mm97I9+nt7q9OLQv/BCU6TfKYJCcjRyW1IsOXEE/5HWlNffLwpdUjqEt3U2BxiqR7ZUhsD/gh8IsMMIBqDT4x9X5cqKggZnX+tj1MMZm8QZKvpuM92mEoDna8KVwEnnC5JnCf1+VRESICr5Rm0DBrcZjOiYsg7CvxNA3mm5IUoIE5K0k43jV9t0FUFN0ooGOFN8IdpAxic4MMRFj7AcLjiIlONwcM146DKBz5kKxFMEdwDJKwLjGzjIcElRIqGpERYAoC6sOv1i/RzbcXyuhSzDCuHfRdElMIDnF60KF2H6IwyKIt52ic6RANXHc9EdAQVTsP/M7jkvy0yuPbQ6NFkeWpGaRuJWKLryn1gtL7leqm7TUvS40G//jCwi1UrZqAnMCQSGHdHk4LB6c+Shp/GjoF1SNEjKHHtJUvoGRbQmRWVdE0vKOwJetD86xE8kWfQJLeNVKYsvuQR8Zw6zazy5soseURcmVuDWvgE4EDEjCAFGAjq+C3OSLKYAZAamUTE+DMiIsQPMLCa0Ko8gM2iQslLFR+hmi+yhOkFWZ+065UeVxYsFCP6kq7EGFLqZbEPbt2qk84nhU+V33scNglltqYRHUyrJQaW5jJ01fCzuNeBLzTZQV8iw7AOjQB2tSMCNZy7jcdgS11EME/EwTNNcIOtAauQDcG/vqHLof1alUJvuDpDB3JEEeCCvEIUE3fpVTAHzbj04Tuuo+JCjlm4/bWDkiBUQuaPVrVEJeymOekRHhW6SW63nbO5YXtEYSs1pJDTBP+BLYLHJHI6jB5fBellvCqWx2JIMvPpMB5W5Paj/M97J0yVjdlKenUpNzVXWqwkZU7FI6OtW2vmYWZV+6r3uR+8N8nVy3lmAJV/zO1zEC3dg7yiA7DKGmWyYSEs4XXEyymYz1B8LzxE7A3CNkGxroImWq90yjoVhqOnRubfk7CRXWEVD3byDGArNA5+3iBsJLzhtXIxIkkBNdvYZCrHTwmzwLpmM1fZLyizVdThZ85yjT54yh+/P3kyo3DKL516HBGDyEJ+E6opEuIQCzV4CyhducuOzopFQE2WDKtxpAtH5BmYeI7m9i2zWtnzNBovBUppKtjojIynQyTqyEbQTh8aQWBOrNMd35U7vzl8MdXVBUoEImhXuQDOz/MRavdSVIUt/5/aa4IX1xuiE6590oZdtY0mXFgZxpTyPEKm0i1sBbupC1nNrA1dBiOb/eNURQeRhaxcosMTAbcOlRCeQr4Pzk66Nj3AUGl5VBXwOrJMKcj85viDOsRKTi06QxuQ5McEQHHT4qVTiiawNniO/CXzYPVfGro6gOnM4bo2c5McBSZs6RnqGGkbbfv8niLh2seDYGlvfpscky0wd4EljFr8Ko6R9LiCoTMjVbhRtzl/qbNkOn/xUhgLWN9tL40odesTYerlsXwaKk9Th2gUGvT4sMFroAQ9Ri6Z5FfHU0+jZMSB6vVO07jhLJWEs34R+EzDK0fJ5prZ6m9m3I5bPmAgMlfoNozfazLhG441p1LWyNXYkmy2wpH31uNWOqiyXl3eaEU6bSweRAZZT6QjbKcxpFc5Xp2WY0ALsav8k7qXw2a9OQkWEKzoLnzMYko9cJ8c5mrc7I64WdigQg7FX67WkpfB4MtOWi4g1HxfDxV86kxzb0F+RHuGzVbscLSN7I0ZsvktsKGCNyBKzccI/MiZD4IhCGBj42TFScyfGc8cscqRdt45lvnXm2jZJ02RhC4ZsnErstC9mB4FLBFogS1g7cP+40znDghIg/RUhuuIXVde5qYt7w4TpRABarcMwbjyRAQ4N8mppwwmwUtLz7zKrI9tvJDE2lzklaRFR85tyUBSMkhIEjt7YjZJlpZizOZxtD0Xi6oGfCgysz8Ikxn240eAc3hG9EePBWjZhDiGyLxKCx617sgiT/1/qE18zoboIxRMt6EitWxXz6uAa188XrGtXN41qykcNWFRkk/vOhuik98pXtW7uMGGviEmuy/UsaIurfT4qlNHG1Fk2dIaDl0qU+4pXMsk2SS6/v2F+koWDuA8HCuTl9sn9BZqvjoHW97ZrOirwRwJtGbjFhKgO1RUGjSEu0SkpTCj85jZESgBHceB0QxNmYgJFBIJX5e3vKj4VCjihQcBDaMpH9sKOOF8uUvmdZ4jlX4yhSYjUixtCFfV7yzZk1dH2w4Q+loA0IEQorLebp7qz2vjnCWpBkOUhZl1jzWpCLBMKwQoBfIt8sw/gsPX7M2L/8+YmgaIWwPh6iJ43cKEYIbeS6sNYtM7Fl4zqL1DydNHvU3N0O7bPeZR9ZhM6uMeSse6e8+NEBj5jFU+YTbN/IaaL0mcIdsbZVDatXSXTjzhHeNr9marcz9Flj1ayhhsyYRQHS6qzojtDDPKvHCk6PWq01VJiesxyjsCu9LcxBTR05SnbqdlZ+W8pJghWCRZTi2pnpQu4I68QPIEZSdYsJO4w4sjVZyjLm9MALZWgh8zOVUvR0yJyVKrn3PARQ6fShdMmdLntaJWsCbIMRnUlsSAKrbWU5znmKVtHH7rybLq/brRyyOQ5TnkU5EmxuwoR9sLxYgMnTPigL9Mqjb3P0RDwRliQBBFRpFxsC4N4Ka+fdKEsV3X/AkKhBqRlUSlS9GoDxGOJtmix6WrOveeUcBUPIT6lqXInCaCdd6mTF4b4nMdq+LpZ+N3OgTzu76bLcKVQE8AGqhUTadQBEpYw3+cTwcQ8YMesK/SGEFxdNc1BUg2VJZBw3Dmy1D0660svFyCgTIDwjEicCZk6OlqGoO3JTD3DvFJLRGFMHWHJ/Ebpb8DcPUvoHwrnLWTnPr7U7LLLTTP8L6TSXZW9PPtUvIcQAEkQKeq10DpfkMcicEGX4ktUtP9mQS3ojWn/LLyj+RG+8rXFBaMVgkaYPAvJpLpp4HaEpgIsLkmlK74anLkqYXpJFeg5pHhHlFnNjjuiUXeVRY1nzm3H1qzw3VtI1fN7id6mdo6m1iNvna2uJ1I6DtdG21XUAYQAdvHQVpbK4eVZKAjlBEX+GuksShCbDEKiAcxt4b5CVUhIibvrchOdZVEwoesEFyHCayYFBaQBkjPxeay2ZQxkxWTnjWvHfr+lzy/3YUFdbQRZb6h2U2xofUeczOLlSElsqFKkHfirC9lr4CiTd5nB7yNJTI6KagCVgBtUaUZcttjSQvbAY3gp1gGa7UGIDBXZZ/Rpq+5u7wdEsoYctJTI4TgEZDzI0sKetitd0x5IyJNzZmuVvs+sRbIql/yKCuNIykxTLq699bTtxrKqBLRJI0CP6MSlal8vu9SM4EFHe7a8jrWM78+qvyS39n7F0JKgHhwBHcI5Gk8vFnuVBgHPoC2t3+ZbLItOCFIIjGQn6bM+gVwmODxf71MNsh0k7oUMMrlTWYJHKJJTqlzPgD4gUEGNxGAiKxgoAr3b9mxJJ7jjjRpFfNw9vRDpUzVnb37Cl90Rsp4J8Vwrsv99Z0qn/v07uIU+w/KkbWh4uM0lUCSKgCfHnfMIvplNqEJ/0q6no20FazZBrLzdxBvFJChb0b8z1oyzWCLfCdAsRRD29kpZq7972ffCX9IN1yxdfKpfWOKqrB62W5DYwUgGg3YG/UanoKUzuZzVzx99t/VfYPLNMR6O5KVtlzYZavIFid8AtBAQvBN00OVeVBZ0C4Kj8WMD+VFCyhH3MUWw7/P00Jq+3YumFvcpht3robSjpfY2CLmTBVncrcqfbuewa4G40kabE8ooMJyRtjwhVcL1zNknUCfuNl+pF8oQBOd1qpvIrB3cZsyVwvX2WKdWgm1i6STfBVGqkDoUCLoE4BllhivEHghXIPtQKzRf3i1EI+999EfgbrG4GJW9yHJASK2xELc34tRJMOpqEvwkkSqJJSrdm/ieiTdZo8/VCoYrWeRLALHP0XdbeG2ipL6Vu7nuCDNJbloB1cgqxLMEReOeekaLC1dj7HNPfNcBoMbAA6kD7zrJnjtwexQ5gsbBmz3a+6g2c9wNDlgJSHQ0ZcLc4quEonX91OzQSZxKMoD+45q5KXDtr8Q5UVRJLb/z+o+KbRWsKS4bvVeouV1bVd/+u3qJ568a0oyi7250wTJATkd9KuDIXzOdrDSfGZFgTDAR2AW+GW2jeGhk1iIHQ4FipdGnirEbI9eiZgN2DoKVKSDXKRUkVM61hcRcvPgcbBhENzCPCxtGXL90R1HZ6GX80YpYvDqINyGbjWrMjGtEv/X/ulNT+oMax8JvftioP8Pes0jrqcxjOiysd1eibmAEPAKFg98OCip40cKmk0YVphXa9V9pecljsOwpkCbI2ST/fVI/qSFl5VaSEr00VfFsbjaw1IIyL6AsK9+9KzjJQXu+esskIlMcoyChZl8VHtV/N7br1uoXSF6Hyrzz2E3F3w4A9SpY2T7rV9a3tRZ5lG1AsOMLCOg10GORFR7SbgvL+uV3ZsyV80LFMBjQra3e38UubbWor617PZd2ddNgGvcYGf+/c0IaKcGy6/+pLA6fXuWxfb+QfIR41T3mO2tthlLylP18xrDl5SOPEaBpKldzaZUcm+ZzYZILAjcHxhMgukFGA6oRuUveb230swmLd8FdQOgLEUkl8wo19sKnYxNEyfz+Isl5x8IZYIZEBiUjYCXVzpITbtXh3xqA+GbpcChpq+z8vItedcVaHSBtz0FnsgytTpnj7HrvLdrC7Je7VqBA4yg7okMUAJnKXQg3qw6xf1+9y8Tci4ieUlJGjDFj0t+MfCORUq8Vgu3JPq9ehYBBhNRkB3xFmRemk/q8F/lP/b1x5jWlqIutqbsrZaRm39s5Npp5JrC3vmVnDmRnsjoRPsCi4BKX6Pzw9FDmrOaOKnEf7nJZgSgLcIKMOGVBUgegOCJckPgaIU9GCQV5wWhhcyXl9NWIcKKRhT7DW2s9InNjLzVHBCCtaiKdrSm7L1qt/KFN/LXd2yElsmkjEtEVGKtmsT0f8jRmt92ZnUzTuohMJ7LtX8POMu+JSAqoPqB8AbQepkE40kpLfsTYbRqinEeUhpazrGOKuUx8VVS6nEnEzUjFqqedzomuM+taYr76VmJOpzZvJ8J4YgMyUs008VOLF4MW4NIX5LDcxWMqCCUrnyjsXiq0CLigEHJGFyBVAKCCJBCilELLwIwyL0XD4X+SyrgzxORShTS4rwujcLgUGZWU2i3/WLsJ92NcIraksbR6xl8JRZHpep64qM3csc3scjIx2uRagtpTCl5dW8wKElNi2x07B2uDNm/aQ1IegF5B/QwA4JKCMmPNAmLmdf5hZn/QvUSnH+O0QdFMhZp3l0uxez5Ok+j9fr7jddoy3y6o3jlIk5v9JHMlk0kqc2UY6EumCoqF3E5QsnNaBDSZvrMFHTna6Wc4cApzMC6B1wbkFGCBn3KsdEUUlKpeVp3KOCtK3FLNafg2rdKOtLJqSVGx1FvFoX2O57FwWz75R+892pGYCyG//4xQgDZlYBgv8h/S37Jvjf9sv0uPHh7cfqyOtA7gq1Lc7yAKDX7k/qhd9kjCgMApeaizDzkRrLTd/mypm4hDo810/9K2/8vko/IUvFzIS3LR4DRI3rws6yvMLs7CjlHIub0tJbCynYLMb5vHQd8iD0lXfJl2OfJ220T3FVNWjUflpB8v8V5k/iWSAbAcpZDeRUpYvUxxUXwisR67y4CRp9ZB71+Jup+SauewuneUY1+W4SXBcRXB/jVGQLaSB838NWIOd4g7IPAR8gpFnCQrnoShWuVFLRbLtuSJkvIqWEacPWH9XNeisZMdMEjHlSG4WEaEHPBRUTpsKFhFHEBnywCTejKX1LHmIxkONL9ZxE4LIaApxSCrG2MMJAJ4VhZlcJYThfmSQBRGIUzBVGO7qIdVuybmLJOdESMUsi+o3DMn3DCllXvyrGLGP+Iem+vIaL2blE1uXpvp/YZatxQn4kVimCYIYsi4EYJQXY2B6D0HyMUXiCgGEKI6jfKd9k2dxvPBWO1us592tLeb805pW3osK9ZBRPxFTJsKkKSjuhaRwc2g7Cj1iMkxuCKEKrfvQ3ZMUs04gEIzHwT5qEScAiB2i2HMLoJISwtDLPIRQgy8MomDHJtltNSpJI9v/1pMWbM05uVv5yKdMXEbEt/h+JJxCwsoT1V87NRDxvyox9KiJaCCbmfLMy3updNpSEf5uGmLU5xHHygyBRjXOA6y7ME8DBLg0yRJYiFwuE0j8GwvTaV7SdkXY/0xeiYcxp7TAoP8SEichWws7u8mWvCe0msuZogiCRKgyxemUbqKTXe3pKHQVZrlmIgQgjhyDDNAlCcKgQIlhFm2+StEAXZBrNT4lRdy1ZrRfTzurxcpsEFFjE5MOs+hWl/RIRk3n1PwY0x7oyRyjuP1XMCjdGYx8pBCkticUUhLIbBPDKO0X4rQiBnn8114VJynsYbnbzvaCnUfjqe/r8nnCUgoYZcRFBd97tp053aPlyfL1Y6QlzfbyuuaEW1OVQJoVKcICxcrRx3JfLVvutidQnRgCZH2HoHsGyEKPYSjtSDHIo+i1QuuxrVfplyNnJLmImNqCKgy4CTgbUPPvzTHOk2/UIrxEqfnkKwItpA2f3jUtmV0gtNN4OkzyYt2hS9fa1zCcNquGF1PabYpR2RRRej0G0LkSpo0GzjNCMkKQFQ8949bl7tPcm0tt5mY6sKlGVivX5wyWURtr0cEtG7Omr2O8amks96qv5i4FOqb6BQEXcWl1Gw9PoXgRYgHmUKzjQDciWCHFQEEExGNKS6zZN4xyNbRuT0N2l2f6w1arWumYlBvlNLHnhd4ZuOPO7p8SAFnFkdU0wSodJVSndazkiUZiWbeuoa7vOc1sRsLedZHzUZSvSkPa32Pz2nSSUDrBUBYDRCAH1MUnaxfaTRGaT/L/IrJJ04yzY19XWS2Si3l04g0KbD2QhEIxEf5qPKAq4ZZF0tCFBoUjl1kFy8pEUyVilFiHXSn79M+oIgIshEyto+XzVvMleRf0td4IEHBFgW5jSiibGGYlCXSfVymTY4lDzrd6ectYyQiMSKKPKLM7F5h/IW2EDikXutkBswF7EJMz1ISEOStcXK0VF7rzlUx3IvTSpsm4N2VITJZ7YzGVO0LYtOombEijBGYDIBCWfbXRnRKeva1NMQwp5kCpl2KgwiBJs/hfUzNTK5a+pVNZBb4zMTvT1RWYTCHZnpruB8gYNqj+V/GIEqEmufYGsc58iHD1db5gWaQQgXASRGRcQ1PEddjjbjfFbRZY5LA1Iy6x0Y050miWQlxwBSjgErIubgySkVSzWnKvIWRXhtF6urFkJAb92dmajQwQqGqhx4TmUuC6ADZBuFK+1He4NJfbEU0jeHQgcfUBsQWg1FBb1en68u0eMhI8qkPIRE6zCoyt18NG19aqb0u+YjQN3k4FhKY12HNFSkLrMZ2z5NKvcYa4VKibgWT9YqsUB1rg3FezVqXq2hU02aSi54s5KtCioFcA4wvMTt1inoSyWFFOVVUNsqWdiQps0dOCF0ps5tpyWp9t5QvbMNEQsjOGMoZWWrRn3kt9c93+/KOS6CDyjCZGwpjTUtRNOHF4rsUwqBA6V1RJvDR2vOGeT8h2TXXNO8UyVcV6VRX9TDL+tOXWAjUIkUzILxZdO9cQ3Imwj/hcCylJk5NEQdmpaf9f3cseSjQi/D5BZPpFhTiUCQ6fsLmNOceTYVoo3cRq95UiW1A4b544VOKhkYYb3Y4FRyTE0Jx9nU1u3CnA+Daz87SX57yFfM9+Idt0/1+7KoJBArogsOaqHvsNwCRImj2Y0Z462G/PoSAuHkiiT/pNWkjdyiSEc6VVl6Oxf6sF/2i0K4/qnVtbQN0A2VzTH+V77VohVYTylMIM8Efqb4pp9FHfJ89aF4vtbGTPmJLRRFxymG8Wmume/W133XUvAyOLzP03dg90OOFhwsOxibsKwLDtDpmPsNKKrYmz8+y6fZjLiCaZdghApn7M6Cdd5cwflVcVW1kHegrQJmR6X73HayGGcYY9gwRX5jhs7WUhYzVmlz2uocFoqyu05My+t75lQb/C0j5+W8loJaNY3VR3bfnn/+VISpZl+pehbYPaX8HESY7JBuDY7c9DWkHdHovxS+8XymgM0ud+3vb8w0MiUlC06gva5FK71I3W1AXqj038EQUf6meOjVmLMUJJww04ch5kKIkx6lzktpAS+8Hs5ZwrjyGdNJJfRe5n0HZ8lpWaD/D4NTn6t9dQrHlMWNYoowHBjRX2xJVldUQpVQlEfF3UFyDNn/MCloVbUmNHVzkXCJNRma2X8SDavfTGJuBWz8bu1OxspC7Iq8fmclZ49BmiHpLDST0HIxCOoEuqoo0d72QStNpgfOhzicVg6urleqlShbT7/101b0BWVF/fe+uFjBMwzb4twJ5LDkgVEHpwKQBRHud0Wc2AsgDZQp5xHye14CbBtBrJ+S/c0iuHizyf2Gi0knmkK18TEpHQOcziYb/318Roxj0Y/YRHeFkfqH0RrBQHCws09Cu6uDP0r1o3VMcl82zW0sIhKSrK+L1vSQ8y8lPlVnykOrmIU6N+462bamekUhtxL9Dr8HMNUtFPaA8DI2GWKwrth+y25sfqd5TWB17MP1V8hLC3xr1m5sDrlxQDf/z3MyjhIRufDlHLKRJ0mGxHSyELWnbIKWuXJ6S7qBofl2d/vk2rI4QvveJxD09Awzb68V8pF8Nlas1Su5Vn5jTKRIHEwrJ/9BBoSnGU+HyRyH/Z/2aL/XLIHVEnTi2/BcQrdCSJrh1+NERQ01x2VCEHJDvj4GOJohFmeHqHwOYk7S3fWeI2huIqaF6Uka61KgpUky+4Z7gMf6eC28jJMZaPMijs90MB/FAa9M+RsicnrElO6I2bEjYhIy6aEWX0dkDdiQoSxQJ8ZgKWqtaBHDyTtF/63oJEBuhireKi0KXWcQIt2rSmEX5lEHr0gcPyocxjaEGUL/NLT248Ex0X4+VASQrkdYnV8DuWqEIW6kZHNWyzoLHbxDKR2OZo7DB6VfZnJPZGaNhPWQ11/fRVVWFaTGiriQjbjmiQ85gE1GdBIxI2HIcEocA9aI5wJUappIsxawj5A4AzFdITk6RYC5Itj054yoZBf6bicXC1kZbsJRtKp89g5C6RLYYzofxWlE67NwP+LArCWV5LWls2K1kKsEyusgWJVoz58TYqshy7Zjj9OP3aXRLab3Vj0OrR0p5txBTBm1dEqJT3P/rWm9E1fngqY4imb1c68/xRlWnkRnjmC6G24Hv3MJ4jYNNwolaNFIrzu43GatqkA42wllkkch1nQ5noQ5XkWqVsnMX3TgEiUi3UbB6ua8bVVacXqb1fAwDG72wx6oVDERzH/3DzmOwKcSHb8/nrC4rR8PjsKzZUzKmLeVNWJJ26bptH630fFZpvMYX8zPrk2HUJAyHgTB0PBUJ5kLBOGEbzK4JK6oKLwS2cvkgiJSdv5ae9PZgM5ZJzMhrBUPYnF8uqKViYqDrrD2nKjn1V35ydhRW0zYZ8RgVEgkkUlPC8yKPJoL2UTv6ly5EubZQiFHKLsdYtR0i7GCEWP8dJlqlY7rx6WfH+XV+KrWJZqE8ovpnwVh6BoDMF46N3YVio/LxWITgjPRu7LyIVj0OAhDMyFAnB4EYRjsMTQaBAOlP6l9bMC7Aa2HntObSsq5r46OK3bY4EDwqS6k38kRZnYUYKrNhRzXjEUQeJrNs3eQRFP7CF03+SqL60OrmYwSSrJItKr9EGij+a2HEqHRaTOHtiUma+wGSJpmM9CMtMKpdtBTJhBMlkphlMJB4XmkIoW4hdAg0Nhd8wGJp1svOKhNrWIzQvIlZLjYJygZEKi//oVKOsvROBIJrxudwePCE+TJgYE9CL5kkX3Sao3xL/5RInM/S7VnQ/DSqSOzYSdGRmWCuRWfQoT5ishCBbf5m4Xcl9JUupmSyXkzN8O8S8/oIEOur5cBVRvjvpCEAOmytlFMDuyX8bCThneRwf0EkLFYBgd9qgW0JRKEqBU6VsjSRrS4TlguU4pNnD1S8pwtupuRwmGzSjjjy5mZqaZ062cm3m2G/59tiUSVEuCGdMJjcYaKDxiUUm//NWZN1HVGWtWFaluT4leiU2NpbRqaXO7nYSiIc395RqJxmrkjqM0wmUiLibDLQq8EUhA3MDxeiHzP1JnPAaTbh3pl3Xw4yohOfzAhWMZed7xDrDCIBUdrWOiDZYU9Ka07/M4bzEdUFplNFfn3LX0+b2Udujdknv9J0QXWD/gkXAHsJ/0/IleIxcmIYZKykP8CTYMECONmnuziG51ZaWIuUMhYkwJG9PYys7Q5G8ZI+aHXBz435w5Jn7sTMWggh3oHdVCaW8DEJASbYKzsRkLX+VLOJl1rx7WL+AqEGYOpKR9RaVuL3RrNisvCDAyckXWurnBmcCwwzoP9JG+8E9BStT4mNIH/6o2TSrFtcW+A3wEEolp7ZRWzkBNDW3gbVzFun3aKJpP84380nYDXGwcGbheyKY3mgtiDD8habtxJ40p9uQYRhpfSiZdgVrEudKt7EB1JuN4mxAnDj5J1fi9SVtqfQSvsYmCnBFi++XmT0sksGhZCZ42KwhsXV+gqkyklZ5ExsuqtS7xeojzwpJbetMmJRjQXTtcuJCQuab8OPiaChdnUf03q5YL6q1p2eguZFOaON0LBojp7fob9pwhIkOhuTw0vStY0WeM92frNzZxukgFdek8WfbdtmXyDpMWGplvbsYT1N+mgzXzw6UUvkK/FiBBJmUHBIro8vxfD1fsNoi7TMarF+8T/PMIKr+FUooDE2ad0EZaBVjV0bPKwIqrs5cgxwam/nWEIoEmUEE7m4agWpZOT1TqVNRGWt5tdu7y+i7Pz2yKPGmTFXyb1WD4prOoGwb1rERQkoxK0pcoj3KrQG/IkVIfVb6jCnnANTbpsi9pZGMDlZFcYpxfQ+6MZVOdGu61FwpIwJVnqH5BC+Iv4JIriCgq+RHBON+ExV8eStYqd2YQ1eIia9T5BBxbuzyOn5UyCB6/kc28zSDaq5jUJO5j/krRniZcJzH9RNLYq5v/vKonajpmxM5G+oMYivSX9XY/w7/5X+1Sp/o3RoHXBzKnVY4ZXG4nB+EQKuPAX2791e2fW3FjVSNL4AKGieiy8l+xkRGweXYuEOwqMqe7SsFJKWtNa1rgYhzOsEufFLukC5h3fzFcvWWW0biUZUii7poIrP5xuZqlFNBCsWpPt8Kcfqkc8EFboIEZaRBY/NUMtpVZLI7nPoUzh8nKjBOOLfaLT2VBoBSKGiDKcy1Qx7G0G6g8Ws8wKt98wtqqBn6nCxcz2ykF+47uViSjxeop6fPLynWSjY20kOlHIBNTV8pZPKpmRrimCXENvVvclEWj/vDCuTL7gOfn5lSUBl+dcJiHY3aoZyE7QTfayoL/NPhgcoE7unk6ud4Os3MYKwTimB39RFA1mkFj3CqLVcDRI7SgclDnHRGLq7T3QtT49nS6eXoUYklzwhrtRUtVz4pvKklJotOmNWsozL0FybyZ4jxML4tpkJCMfGmCssqouNZ/YNYuXoEU8EHpijcwaFEAj2cqnlP222zak02CSedJ8Nmwvi1NmRJYTXZgnAqaU2YhvOQmaL4GzpnbL7rd5D4hi/K6mFokMedupS10zhlCyzgouNNdgCop3xTXekM7eUWMhiZBidqyibH5sQhn8h3UUeUN9bW/LEjJmVVyQCOKMyYNs1oM4RXbzdwKo8yKPL0kNy/V7hAUlwv8EKQxYNKwicUTWIxxlvhH3+i3dnNsnSDF+qTHy6dV4tqLZ/iHHf+21fczqT6/TTyhzQQiqqhQ29kWKtZf13IcQsaVe9K1L/0KWqQPZnFJBScTaQrY77df6//53BIaT5Y/aUzXZdnpdtCmqwV2CCNIoT+iWr+xvR0UskUJqlTSafGr5O5zm+VSW5SPq6V2V02wJAqll0BQk0E+/aR4L3dQQUNnCcoWNbfZo/Y4XG5hJsfdkubKRFq76IkymUhJSEn+7wvIKss7JfP07ihd5skBxdWtbyUrnJ9xEfG8nnlxfb27rpej76BvrqAJrm8D/+Nu+LvCqpHySTF7+zBPEEC1psG8DM8C25Vj6+SZGfIvN4eGaWRDFlJr9lDk5BIrLGcsA/vhrV8+tUTAqrG3kM9P1TLjmp+uJSOEPYV7sb9TX4ffTqqRFFTcmM7qhZtmtp7QcNl8eaRvZhZ+qJSbO9Y1HFEk8OsykvK51j+myZjel86pNR5RQJ+2GlISKRNRH/RIuTK9ZLSubm5X6dB7d0y5zFqzF/YPVunhxVqEvZN1dVMaFc4Iq/x0thY2SWW4tSulpCE5wkClHfJ9iFovyEvDZKICAchsaZne48e4yUGa31spaS05X9JdONX4mH+pRO8ZK91t5jSLALrCYhL2XDbx/kopnGpCcas3wUYpbJ6+XMMFSXFqp2kSVuGRKYFcTCCyq5AkSUN0zCoiwsKvaItMQ5VXWzSpuqIgYKHmCKufrmVjvz1lagM5vuL4khpSiHbR2+u22wtqugTp380wZFL2NOxqSNL6XwHSxbpH/vqGSIQl6a073ztpxA/Mlv8B3cQwYBn5lKw+ekcdaTJxRU9LMwMeLETnP1ARdwpzSXdjOx8voRCwwz/LjnlbSbZ1uKBHv+uUEjjfVngQ5IMIYFIWMro0CmjuGeyGkGeSxqqZbGS/Nqf/FWQmWwijE8oOvv8c2ULli75S8uK1xHSRaAIv3KE6ktzWZvxGFrQnvLlcyVmp4YVhRu6DMGEVbLxYt/WiQiUmOgb0zdCG69BB0vs/zXtUS9DFMYOvcgZzpBtUzs6Pe/EXhkcUDkPYj+em3lg/2CNwQ59l27wexP5uxPj/E208b/rnDdLuBS89c2TulIiQO2CGKmHVPa/9YqqQsfIpWJS1EJQe2EpLAZnjtYDev0MA/PIGI4xbkdUWOqiyDtYsqTJMFkqt7eb/6y5deEUYQFqn//jFCARzTv6M/+wCl//A/qb9EgI7ASm0pzTyoa/8a8E798ACC2t0kh5dlccAHmpBBWbTbKPR5LhB2ktdGWwrnVHmvyaHkktKbD02dymMRoHuF6pSOxNKcFCcitf09F+sYeW2GtilhuMF8tAUF+zpAoI1z3xa3CXppuH9o1vIoky/dJds/n366RW0W0kI50dXaUtu5LuuCXGItEXlkHoj4/BQm7KTSbQGRIgiYn4Kr1FautE32QMGnblRblUSHEutO0TWmG5+WJNMWysAtr+Ps3+JTPwZEiDYhzWNVPrqTv423Yacv3hhswdrjJRdf0fypbZLCrFUYfQGpLJDQRO76owtMEmTO8rihIL/4U8mD0ExwmdNIC6FENaFrcAobcyQDeHzCtiGB8mqIy++s/GCZuTHKpJruNk8jxpS1ujTWqkuD+1f99bGJzpu/Lj2VwrEFaRVvKtcAxhLGCX/wSrLKePbYJNWpC3vqd8++5+eVykUjg+a5sscNmYz9FMRAminUnWT2owo5WX5GRYi47vZXtopCfU9dLaeIu3clrOaVpCkAq+5CvWxPvxR6zTtcVRLERgFASjUQC6I5gEYRqIs3H4jELHhAYJGjZxQmNi7DJfRtyrJfrZrHaDz+TRDgx6itaeLZLAE3wKpDgvXRnw3LRTPljlUWSHCW+Ou1dkUqc1LGBwRs/R5dRpmeaBmO9eEcxL4iLp97i0KKccifB23ZCuCEf2zRx28xgRHVAwTB6yCvpgox2g9yx0srUIDjTAjb2oq8GWQiwo6R9CggWhGFjuoigIIrUMsBRMMEGIawdGYPN5CppL6le7eWfFX4Z7XcaVcK1utPIe4RyWqNy58sEhD6C3eKac/dPTPyXnUpwXGWMS6h6CsJpai9S2Opqc2+3IcjXAVSLfxbONB6EmR4MrPSPhKg8GY4GrCdEft+auqaN2pmBE0sUWSoCKiYx0gRaKybnDCYHmmKCqTkqrJVNuUf0jrSXMtRbFRhg98VQw+XUQbLo7jmE0IoYil1i6WHPrf4ufyKvpNaQicLECnTBKzo+k4VfsPFHVET5hA8YRvUaGG7rErOIQw4jhEZn1vc/dSJAJeapn0O//sshYxqCg/EawMCcyAv6Wx30yjTBlWJurmpmVyVt+GXs2Avc5rWwc1uvj0m7K8RtblnWbEoSaATc3C+xtJEt+CqkmIj/Ixh+MhvWgOXwEtt3Z4EJ0/cwM4sPw7s3Y5bZ65je5yvb37KOoGLl/AVUkBdXQuOZ/Hz2Evp88n03l96kdDrlNm0rljL5uKeZaL43AtgegRfwlBFKG2KqCuM1scQlO+53N20tjAU4qkm2NiT2i3+ZQJvSJc130LLXudDCMgo3Hgs6tlPmvI8zJFupWmm/CeZKK2yZ3QJoEgNPAWA4itNKolHUjEN89oJoEcuH8RjrDaFv24ElwO5uS3UTBLLTbKYD+JxlXoX9cq4ejVKfM4FV03siHPPxxSmBbZEd6/4qCkvsEeVFrateytpSF8hEVIg/UR3KBTjLhrXl3Aj6bzXE298xtcjTFliGQhzrJLKp0zLNe95BmPa6rC+kW/d6YmdXhmzXAzYTw+DZaCIdHATjU+BS1g7ZzoQOxCUE7sWJ/gsOJCw3pvXsX5L36rkH7XLtiwZHolqrtliZmRzq00zXQYQNyZbz+zVjDrRRkoKNX4iDpHI/y0WWWLi+bBUMBrEg2iIcB2JYuCK6i0tC2Q4wNPkNz5bEsopWDcXbPfyhJYr3JI4clObDRZCNvcIi0U0aepaegScj9p+TOVQCBucMkbg38YoU7giXghdo1bmy6Bm9n2/1cLUXD1iBVOFqAjAJMBgChKx+WITFWNrMYSOXUiEo4Q5FmMSmzwnAUININE+IpQn4apgEbOSCDuqWJWxRksv6jA6yi/WpJKi/qLzl6J/ag5qXmuuYs0Tea6R0l/eoPhtXXEs1sr8u3CKk03KMdvClqdoNEUAOsOQ37YxhygWQeYCGPkUlRDhiXoiNZDZU9wFhlnArRvJHqVhmmoECKaN0XNBakV613d48X+7L6BU0AqvkhFJ1eSCXk7OYKmV8ekqKWoaKsa81pwtvn2Uh2ruC83r9on/GavybESOM0yFa8QZL0Pl5ogMcFMGmNpujy+y8H8R45HuNIQCtDo4pE0laFVf7xOYgoilHYh9uYl29KQJUJqjVkDqZvOVVq6NlpK51nh8kNaKcUnrQPV7OXPi7R1M56T09zf/OtP1jfIZNlbkI0h2Pz8JBlu/VSDVbY9UWXakKHk4w/RfAW4K4FSHcMUG8QYtBTF+YUazAuFGCc0IRQXhGWSsbSOGIvT+oS1Uy3aEYgmoUiVJ71gXrCcEUVXSTULFbX9fkdStKmu6ND2arVLU7arAUO0r2aslLgWqAz8GESN2UvTrr895QTLPFKb44T/dXvRoo1cAbY3gCrAuBWsJDsovvUNz7+YuKEsLLtD8lv1bbZEa64Uw0kkvEgUNLE366XUILSbT05RotPLt8PL8Ib7JRe73clyIaZXX13mUNn6kSSzlaXWmED67f/jseQdU71J/UL/7TZQ87dOWuHG2wwRMifsbHHJVQAwUsDnWnpDEZFj2nBjTuKrVc0gL5yg/EByRsbOTvV8eMzn8QpAmjR5gabI0c/jVLdGq/B/vTiTtR/jIE+S+kir5e6NIoFeWz2wzukrhWp/j1eCKMO49iSqaJ/Fv2gzz7ZO83O2sackK6kp1dP6qujfgvb3nLVQB2gjhUQhLkKhowCcgaInwHamtKSwGTWgulsP0goFEDkiQ4XO0dSxNA0iqCkkzowR8RA03OEqISwUaTWFdSKT4ahws2UlAzjKxMt3Zjm/JBxafViz74T2stajVuwKhl/yk5YjVfhZUt+CkLeVG8o8siVWs8pKm1As4dvDaSUjolU7VOaovOTILOVkQCti7o7ARWJ+SIiosfqQ9ZVD4KewAN9bR/D3vai4nwSqKLtSWJpsdbypLnZrvhq6i1gBCl7zFvqh54daYktRCURK26JiOEaCqQ0b8aAqvH1/0c5bQET021rszN8HfQjhO+iIQdi8VfmZMUzmUCJMo1msMIhwXdrCoPS36shjFA+RzCVXPLDyQRUpBolgBNDsApE08wyrFuBUIKMhUJQRncBZ5T4j6JS5NYu54Yz9BPzTFFxDUXaLdtFq1Sv4gTRmyX19G603GDdmaUZtWNXy9Fe1OK7NCQ9iDQXt2XJDTHwT4Sng0trjQHSDIuiTDKH7prwTpPKUxN2K2nYKZfR1Clp1V7ayAyG1Iyzhz9Wl0auEtMz92/EAbk0LsZC4TMLreQJvEXH1O80BMxw7xSqKyX8uCWKZCb8z0KO5AIAzQsGO4UhkVyUwJSIeKR9Jo9Fy+751mUJ6rbZ3QsK6aRX/Sbm3vqtpFO6uHyXi3OkvVcTZUjqMj211iJh7FAiDvWQYkZBdkov36Z/tVMsHe9MU3au2oNUPua62R5+XLk555joNMA2LiQwGdivvAhlk4EbK7Rgiy0lRtPK0qtY0IVg+MdfCHVYIhO7mZzdJKZkXY9rfR9FG415/lU1VrtihFeevHj1e2pfDK4lzTMRSXQNvRIpaI4qzWtbxqCuKE1QgtI2y7DKuGbVyWaeHcjRcwrrI5xnSh7zwm+5E3mZ0k3+tlE6+aDcGt0rVQ4FzDxkviC0Bc991w8aH+KTP4+eSDWQsY+8V5aFqrxFZzR/tX12HiN3KjUKqy7VF54OqwAj9c0tKjw8uYnSwsKnitTsVWK2p65UCfgTTM68NpCLVRdJhZH9PrCWPMhG0UFF2fEmoRHaBuUo3hu1QsftpYFv33/vFeP+MqVsSH16nP1I3bjcSnV576lcSKTKBtgXE5MJlm9p0yYYrQNcXGVZDFgiRyhrBKI3iW20BM71fNZIgs+pi7BV5ozWFMdcK6J+dvbUWof7rXDiEQcdpuwHG2cRoUR5iHUcq3ge/1jRxWVYw3y7N+FQAoLoMPp/o77nxcGaeMzCueTlrPMaRFs9KUt1YsVUfgq90AbYqdX+aEbkozvaSxSUevykLHzEBlg740kI3zjyK0TSCgPm7HnH3MD59lCrm5MRbtsIsst1j1JYs855a3xcME8xakDmxQSUbEczqay5sjZCCle6LHctsUuRBiIMWcHncHYRIch2dhaT8L97OeFwpPWf6PQH+RdW2eaZV95+hN8YdtfFI0RXNAWrU9HTN3NQZSl/V/L0mdUFz7DAnRIq04x42qPgVQDjR8DXk1QghkeHkBCKUra1EgqyJNEUr90p8hRyl8EwnhrSuoOEBIm5EmhSXc4IP7fyOZeFMWxBPvFlWrhBieIBGInCIZg0iKdbNezbApz0LxcohFJlYVRhMMkKgdBAqNaoZesl1ORJcz8luiFL5dxgqT5iI2lO0/Ttd1R9vhzpUW7MWSUd8qZ8gFCiJow6pxHnuKpAWZzMFHPA5NfODKA1kKeYD6jEmDPD4IRyypGCHAWLrPzhUqE0QVYKUYhEOErSAEUClsC2CMj5ALia94lvchYkAEtdVNp0ZZ9vxjcRPohlx7HJLaQk2ak6w0K3vbguUFbXtw+H9j7UP1odUoBPw3PoF64/uBNnXXbbPkfaRX4p9EdL71jY1hUj3Y1XazgWX8Va8VAoMwmhZdLCiAUDASAog1eDivxgyAk7AzF1vIP1LCvmKkAEF2R3eDOeksYXpgwx+TQ109QoUnwUNeKawDAMIblzdj4B0plDMID3nLxg96Wj0j8kBkYaBuIsjROwCKULh9bjaNAfcSMMr4GUNwQ4aGX+4Q3a+zqJDOYSxT+vlj+rj2qu7ubM0Gkl3ZekYEZniEUkOspKz0iQnRPyt6FQcrtdLEFZ1aEybB2n/d+KhNJ194iUzw6o20VI9abHRFkYLhSOa9Oqo2kam1c5tDTObJEK6ge5SSLhbdlUwMtD1dcm8eN5S1kbDOqLWyZItzucSNDScS7jMPst/D3IeRVZQr/ybBJ7OaxpkiXUgsqpTnXXaF0bXioqkXGxISNkRYuuLPONijdAmwIIDivyDYspFST4u4LiE+xOFTZ1BDETQG0Sop2kXRaQKEsW0cF6DdtqkiUlFpB4kXY9WWFmP1OOlkOHDeNGI9husGtBWvMxHmevy92bqydeUlJ/7ypbodt06GCbuxChRcfacRa6YF2CpxAmbCB8KixYQWfH0w8LGhZMufeFws2SXZYPuDST6LDrZ1ll3RbrbpLrJbaz577QwzqUruhzJXTbe/lXpbo7OZfS3HnK9CjKylqRvdFN5WzG68x5wTqyNHytPCiHUVyDB4kxDjQo4NFjhSIgcGnCw4MHHBYQEAU8FlkjTSAkECz2NMIPGloNRwUMPFB8kURaajZXDh+FUVczR+7I2ZmdzWtVV7k1623UnP4jbqr5E+RbfCo6Ph0OipsKugyPgIjKk+vOseaVaw3JKOKEnxIYaECRo8QCguYMqDKQsTBdSs0dVKDBx5CTUnS02zdTImE2qreQo0msRN6L1G8SjRfovbM1KSFjDLf/ehYDPxna50ZyN4jX4xQNUdBWwDU+Cl8OVxb+WpSkrZt/X7N+TmLVWNa+NTAzv8oIJSKNYkZGhMKlzR9YPkQ0bEVht98mOsGiRFt6svEDEwsmrlZWlU5k70iXccF3KIlOuVmyqreGnafRZV7WjuR3JkxHp33NWoq1R8J+NucO2MlVergrUD98UqbimkSyHMLVKhN0qjHkzfkLM/SiH8vbs0paTq088PXz+nDBo8Fjiiw2eCZ8ExBoVEQyIHA0WSOBY4yPLFHSp04XTrn0aRd5TCYYPrqm0eKB8sORApmyiOnKf+x/8p6uFLz+8lk5KSIzfIjXvy83vCoP5473quYroCs/fBfixn/GMw4y/fFdJUT+Tfftxd8JLX6OC3Moz5UTcJTk0OXpUlF4wKxUSFLZwbk5YxVKmuD2o+NNq3n5QZfKhViR7VaJwUMkZEjUtCxmQnydBzWNCQldErDbPSsto2hJCuECxW7EboE/3mq7bDNcMNG1KM9wzKpD/biSolL6yD/pf2+NTSV9nSQzwC/1IaWbQijGeQymc2vqO1y2Ms2vzuXxmbKT4NwgbBSCURHwaAhZmh4KhEUBiRlKZJnYcfxLwof+ytyLnGAxrc9Xn8M27pesYoqBsbFhYbriM1ZBYXPCd8lUH4nbsFajzhbipasIlXah7PFWcrW7MKBSbrUxebCTV/2f8XKVVllFdNTyK/kkSQqimN5fCCI4hhzDmFEGUey+g+ohMKHthGe6Jw6ARAEoCMdmZiSgzASgEQKzkvX124WjgePSadxnPbuU86mmkkRSr9Tb9yLXqV5yM+F42Fo6PhIXmQoEYiODBMgdp/zhgh74CTV9aJ1aDLpsDYrKRK6QgCaP/+MUIBXRWAVEBwAJEAtIDQwN0A2QDPwM/A18DZAMbtKnVIhwvlHvwDYeHYQbn8fpYPAzSIV+tXgacO9ZR5cmT/k/UPPb+urusqd1LT97z9TZBOWGDtiYDSU/7AC45R4UR8pXUBSxo5BWnYEzZpGyQubPSRQ1jRwETA4SSTTxysOmWC1j8yaUrd6v1vcSyMhIb1xtcnkZIPGgXBwC5lFvX+R4mlyoy3HMkRrCktyVmFZttWaoyx8d9Yj8EFz1r9ylMsot0q/0/WmlVtHGXbvyx9htKahO5KGwA5A5BnYARQH0ZAWgaGiu+IVEbd4+BW6BJOrfhSGIiWJBFa7SoZKFNNIaSzBAFJSq6edmvOVCZwfxVabTkTlSe+ntvspiZRRe6sFR8qrRkeuwqFAuElk1HehwAgB82qIX4v3y3x4zsWEW4vv7wyJru2GybFDGVkSRGMxzK9NS0UnNl7x61ReD36Kx80fi4eT2xNZaLgngsD6U4d4p0GYglEcSzqcU2f5u0LImtH3t4Sii5LW7ITVRcFmbCKhPn7smEzubGrpmzWaiFsBcD5KEoTtb06eMglKxWW9YVX/MiZlBZ20LBAERldPjTtl4beYd8EDqGO89dZovhKNEeA8XKne7IMjx68VImlL6rtjXRkI+XCgp6mtpd+rmr275lWSWwsrzKo0fMRh5ykMqJQMgFQoNAawvu8oUCkLAyHaeJJ/IvpWSVeRsoHn2ECP/l4XBAqnR+oGgUFzhMv7KTdZg06QvTE1FrfwyKLSsUsUiJMWOCrKCVcYCIgy04iWaC37Ty676ZWpSzJLypEbInnARuKaTJEop62IU9MDGZbjmpre90GrNS9uZpVZalrK3LNu5Tp23qrmyq9Xt6wb1Vfc05sGgCUtHBDCrjO/g3EwTFjUspbWp2MOavRpSf13RE38IiM5fOF3TThem5YWIKmos/dVCY4qzXhC9X4LmWHuBDYmXHCpJlNk4dOEV8nSxwuXV8qyvGhgmWUXI6fMrk21k+BpDY6b0YrNNauRq/07dvyt5Ryr0v/7vu1nF7ypa0/0oVZ+YmKWVmgtKdxOEqqF0BMgAsPuguBz1KvBUlBIJrRQgHQzs73yfCy6i5Nyppg4NXaSRCTxwU4erHi/E7qxlDaLtV+b+oy1wwoSEtntacWwYQ48e7aa8SOs0n0kMQ+TL4OiCxEOdvwmORikRqv0Zyjpt9EE4hF2IVg6Vk3u7pMi2Om1rdz4sWs9FNQxYlpj56UCgQNnhxOXbo2Vo8JHzDiaWO2TpJvRTP9hpgo0Sc8caMJEnn2FsO6SjCCHEaFSMyeV1+pyJoQqtaGKxxox41qalXMJPACDRGoDaMkweXFzwPu8OHKqHxdQotXC57Ua+Xbk3rV2vW13W+tUdqni1rqlr7jvId9/a4Ee6NDzLXDPz81rrtJCQOCQQIivG8sFCHuuJHgtQp5N8V8WKDU4buJQECEp+xwcoYiisjgwiiz1P/lLl0W49guiozz3o0vNCDZaWFIuVl9hHASKBBlk+MmlGIPlVaEHrcdPrRMLZ0Zs4bttm9V+fO/E+yjgmuVNrpnYjb+u5m7BO5SHuUaTt3kJViG42MXTg0NhRc7u3HiyP70oyJpJVj+SuBNfslkqQcTpq57tjUIMQ40YCOxYm1yu0mpNlX+sXnSxKjEHGQGThCRyOnEZg1zTofoGAhegE8iIg4mpEw7UwvhRXd3p53aBnRW8XbjbVv1Lw7XiaZNERNsXouRbL5iJwZwI1MCFDKEBVoHIgcpgEAVCTCwc+PBM80chNBFRUhZJCJtRBjVElSlyiZRH1nxJXCc4V5FmMmcZwi8m66ssjBHK3pM2Sf0ILrfsU+MLiD4lhvumHwkuhdEUN8gxdFZnr2HCZo2h/XFUEbjGss57r+UV57zYr9Nu6qA+oXE0hl6bKL+TYKCYJDpQjkxUCEzV8iRYsQRW5kFFw500Y9Ip4Bx5gPCIMVhOFKKNQSqeVmDVRQgmU7KC3PaULYvE7me1QSOpn75R0Go0AcgAwSEoeApgQJXzlO3Ehoj3ikyvIMPUeImKaT35yX++t9Pl00ngsamEo3fKRAbmjSmefGwsbIco6yFpyy2eQc/B9BQwxJmFCCEnvNV+RJFikWapmiDCJ/rDhoJE2wYKwGt5gzln14Ilz9zyu365V1Cyr9mxSevIZNtZfXmEyycs/jN6MS7vV9quLxpW7mehOJUmZnHjjyIJKJQS7cmVHuiepOT6KJ9MU1RisqbEOYpOlrkYpBTCzcxydHMycYOBihENRqExIM4jBDlFshUciFV0Urc5eK2GGlG4pf9Zar/CzBYg1i0EkE5tZuXEb0XJUpFJ6/RRgpD1ZIUgqK7dd1yv+YVilEKRSPCRESQSiQYjMfMhysIhyqKUgrqYrCKI8iFI6GRFKsw1i+vkbSUX5hLEoa56t3Jkp4/IVF1vMDhjwkXhgcELu1sshwwHBgqHMFMOILUeri7+304QgUMcx7Yzkk6JMIUQUCHBO0xCY1RqJDFDOEnGpIJxhQY5MbksxJCcY+RimkpO1l1QhxFqKcDAUSXhAcbrpymLCFkLjBRHcQuY2qb0RE4ms+VPxDXbZDYZssWy5VddPXlq9ksWQ0wkQ10wj2V2uNNOazl8x5ETiEqmIIe7YVSXTUoSpZCURbEsup6+pIoWVMq/EeiyIUitI5ujiP2rm/EdPRCkQ5rWlbdG8zVlIoikqFBOUMpSH2kbDPljXf2VWqjUbVI2iDzPq3EkY8Q2GPIicm0VKG4qNIv2Sk1J5H0wSEHjBoh/csj+SzyjxRaMmIRsypqtMElbzvarbGJFiLojTyCHiER5X0qbpqtUN4n6dkSSaEboXyY7eqVac3JDNmF+WpStIWGABYAqAHwqABIGIACZk8EgCi7IfeTqzYfeaxJRIMNH2Xr8e3e2d6qJvQg0XApggjEWEdJe6/IQr0DvXMVAviK/R9XU5MftDBQQZ42xA5P57frTPopGdquEhRKL0R74WDSYSBgdxIT+oQmu6ZU5qw82UJEstk8ZBCC31PG+r3SP/7Z3iYyYrvfwsJdzjN9FE0VpqCqMvpZ8spsDpyZ9SjRKyEd9X5Dl5kVynI8jwVXqIvnC6a5J6XaEj3JarD3U0b8Hye76JUXtea5TRPR+OqQpKtxr5QiTotlpdc6LXpVERITtV1t/wjhQrnjdDQy7puSwTLuXxXf8uYqudcqyRLzeszWQ0LUaBAorlflkPrFAvZqW8xCEwXLEOL0ozwJJj4kPAVuDiIj8NK8bysHC4R0EEf9a9EroUKprCiXKpqJUMoca7m8DXbsF4XELOszaSuoyuSaFdMFXiDKCQIsGrF7qZ5blyPIPZuiQ0k2SEctvYRlHUs+u1RVEQqJpEK5ikVye0v1zvtazmjiOG23FG1IQ6xyjPrTnI8X2lbdiWBW604l1GQtpzxNahhR7H0c10Xmoi/R+e1TIxKSOPURI4eZC3woUtvQ/StIy0fFbS+fmaFeRZ7PRzfyBQmFazu2l5mzOaIaRh9coEqZ1R/SqXEshz0NIdPeg8zKm89187UEFufHIJKXTCTNI9kfZ9Dk0sQlE7CIxcwISRD7KlZRNBBtVfENddsjSmkPMamwr/v9BD0mS8hmxyhEZhabiQUZSO0MtQxyNkTtjmcEFNzHb5NJBBzdU2jFJjdW9a6ohRjtqI6Z21S0RUijDgg7GdkQVGUy0b1o4wqbMQHACAVpCFBjmdFDBWvEFGzHRJCfggU0iKSSM5EmTK4ILjKkMux1KNl2yz4VulfBHsW5aoi1csxudMENRVONK3KxZn2c/FJZUZKtJGOEVNISk+ZaZcQ4klGfhhSa3akUzm12VmHMYcJfGKEObl2mxSMVrnbiDsIOCDku/bFJPxDmvTVN6QKEWp0UmKZUcMHIIrSadLrK1hiwnoh0lbKTFEcR9pxBSMFDFyFoQ+M8JHGKWyLkcQcCA4IXZLoYKEFN6S2CCiOk0kTklkUichWnEK31bk05CkcIKMUk2UxwwKAgKCBwhW7axLxnRBQy5OykshOk2lEKZUAd77/+MUIBn0SAAsAT3FfNqazDTXc8uvy1LtTiY1kS3N5C4m+LhboUGUzeiiOMjgKVt5VdEK0QrKryKOCmQZaRJokRJeKYpJEJiNSRAmp4piTlpyK3shR0TjTlsTVzZS0vai1dqRwmRkXFy+XpJI5aYKvKDWUUCWfEcISjeEeFdkr1IKiIaJZUilznIkhh/BVy2bFuzsV/PLftd0JlpnZSFrfUSL+vxOSqaSKlS4XXlpsi6iR5EXiEMUSkEt6S+TRUL/JHEJSl2xKRE41M6qaVxqotSaXZXbkk8xRbiq2TMkspeuI0qE9u1JV75UULjdpUTT00XnLNZORPo4tRL8aYvS2SdF3Ipy9oiHlljRYTyNfYlr1LSYuR1rInPUdUjUXc4vSNknOlfXFy3HNKJPiHIWSrxbEOJWW2uEJXujRRVKjSkdCz15EyvTJNFZk8oWStNyiW6tcUtHOiV02rUowowo6LxDrKxLV0oprLXp6uhiUXOolGTKIxEXpesTFqmoxSc5TKTu9KitaXJb0kWndiVkmUVXEiepLiXG+URiYtFEmLymcokktbUmROaa7Il1uMUJ8diPFwiZouLJ5VorXE3ziJbE7RbFKqdUTJuqZYrS74yKVktbXXZLSN1u1V8rKcVKZfiLSnyrpSleniclLRGtVOlKcplVLv2lk0k7WZTEStmtkK0TcqZRSYwvxE65IpZZomRCeTqky0Yl6OliTU9Jqqq/RFC/fa2VbEfEl60k/YmqPWmiat6YjkUQ69wkYS9K+C7YJ6kRyVzSE0jV3oj4rq0tCWmTVuvWlkyobLLKXwyULUyVsli9RlqkpcbWsRlXZcRW5aqQK99qYkTcrnVymWSFIfqtabylKTTVbqxb6SOVxI7TS16mlK0icotiTWnUasQq2vKEj03KJZo1mF1KrKJ0lOrUrTpM1IvEOl0VfZE6Jq12iim+VoL5ExSOQqNLRSJCxZDi0Tl6NJS3RyVCnrifSJyOZVtJ6ZFidZSy1F7Em71C1d8haqXJCzKI9QtBHdSl2LXOVKrnyKkXJEdFKtenc7mtE/EfkpE7yVTFITt8cQlfLmkq/SYti5Momt2XJiiU00qo0SWppjUIp3B1LKXSyKI2T5JXP8iQyqa1WUZWKdwtUasMVwjSlRIu15lk2dNkoIav0lxbEu0quk0eSK7w7WFEuxyeElLMjEtJWLKHSclchqCUSd5ZSpFirE/U5qLVFKSaE0iG9cuZHzeQidat04uTHuCgsjbWoi218ZUWjIkognL1OkI01hJRLdSS0QyWr00WXI5FybTxJU8ZLhBSK+n0yIzZN1VIXCH0S2KNqSdmy+BFtFIS7LZZ20gWk0RswvZWUMYJPaSpFdyLy89NTCQ3+iSyZgijIgjqPLSXX6RwgnpD8uSTRrEyrVJMrktKb9iPIuieJeUgJMeU8KO2lksu8ySpFi2FEcW/K7tTWSEUmE3yNQuI/Xi0KFfOUi8foUCyzAyEaJNCdwRIykMSGTkSks0SLZRFF7YPhApuIdXunFUxxKBFHPcivTUXuVoW2rEIjh2SREozR6ImcFIsTcjJxIfZF1+SERtmwiQSwxmhBJbbMmEhbbcgi6WUtB2REE8/klx1VEWSwpjK2wsWoT1nURC3s2hEatmyp0XKFJWdkstaVek9HSlKJObutE2RryiMIWv7IkQmbkIUnyI5axJxDjxHCUxskaE4Q+Fqj3DMRZ4F92tkiFCRkNrCFONI5FzeWha1opLJEyWVUhI3ZZFLWGkU3qRTIR6rJBet6ypHny2umOUlE3IgnOdISavi4RoZSYgsfWJqsj0SEUWDmnwKsXXiWUj9IYRaHO5ET+somk30iJKvO4USN22WI+cqCXUzSMhaEOZJiIxFqUkIWz3YktFvrtFE1l66KR0lWqn6ZIEUIzhjRCSh+P2Kc6aFsLSfIhIL8h6pFeSEiH6yCCVRmaRDkY2GQkQkYzJQkkiaKULJcc2zaxIm2ZIEWTypL46UuYfUxw1yUTI2b//h1CAcKfxlC/+//8LUnj1qAJaJJ3WssLBiuIzEZJpSTkiLCL1GhCEyr/ETQhGmpkQnCSuJQIk/ImiLWpTI5oVEiqlNPKbSGXbc0mIkafSdLkE4Iyk0C9IpbEmILCi4qJIQTX7QyJeXmtPJbnZMQvExXIoVrC2KxzNpGN+ZpMtnMyekknme1CjxHrLIyZck5p2QqL3NL0IZ7KFC9LZEZaxKQczJlP9mzTaTbzOEHTkOKrzE7nA1n7uk0cbWS0ZizMR5dFOxMa3CRRZm7guEHQtMJmFwXHgyYiOPPbUfw0ZI+Hmp4SCHTzywkliEeWxqJkjmh/KWk8yRdFyvJIuFFqLAjIh4rCQjkQyEVkKx1GoXWjtWRKGTUSREOslRbcVqp6C0So4ZISWTI1BhQoXphIlpiYiLElgWeInBITEksIjUogkJD0qjOMJrJSlMkpAoJIhGiXy4JLgv5KItcQkCs+IZIgSQXkI4JwSIEkhUDSRQJbEJ0UgloOKCQCCbBpUQqZvQiSlCQIrsTQLIGR+kK54UCkVZbxSE0zcRMkJWQ1hChNgUyJWFZW5IllEvwrieCJLmmIhBEsiSEJgStk1QXRck9mLThFmtCrbWhFBFjrsThDKiQrhTkkNJLdIaxQoRUIiF5Lywhajffis9tViyi+SWLRP6MEKoSDShJZKkiNIJihGi9RLeTNGEkFnMiVpMLQixWURFGmoYTBNMlktlKIpt3oiNaLJSjjsoCIWiQRCFEIcQhLIzyCaEqYsSjkBIhIcyYgiTexIhauEiEKDkoUwI2JQpWOKERkRWlHuIJBEJtaJCtz1LgriJtSIhFKagQsQRHJIxLYiSYTnZEQSSbUoEUrtER0JkQp4SiCBfhTQSs+NUiNM9XPVEZsxlpcgZMmESI0lgi2F4pJKSEKL8S9NOELJA3TL09oeohG0pFWUmC2go8SI0xomhJvTI4FFr6wmiVkOgQ7iMi4EqVtkkCNBZJVkWETYkyEtFjMQIhIpiHAk0igoTjEupgiGCERLUvmAsKCjWLorG2aoIkU20TItUEN0yIQqm1kRBYSkEzcGSEIEgRwcRYEEQlxJYVqCZFCKLiMQiBYIRBYVfhQghZ4kIskbCIhCbXQTLThBSYzDMERSGeykFGaiC8CZwpECU9BUIpZcrCmjYmAWEJBoVhKUiBCKnyArSKoIiQ2UQimisIJJNWitxBQqQt6GRCEl70UpKWaWxMiEQmrCJiQgWkFIEahEJJURqCRFa2R2ixEhItVkkyyiIR6FBYvqTECWVsitBkQ3IRohlcYiFEjWaa8CrhKWhITqGJFPppKCMYmGTVlFejJSIleq0RLCMPiIQSQkckIxCy4sRSkvlKKKIooUFiHdHiUkiKs0xQggiUSEEEIXCIgIRJHhMVomiuI2QKT5IiJJNhbSCxOJbf2JWkQSyFmqLYuIiS5xCC5SIQopMhQTBJowohBYk/Inoip6yWmkRJYncxEEIIjIcaQiGI1KCFk5gwWtFMgJXw\" type=\"audio/flac\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "import random\n",
    "\n",
    "file_id = random.choice([f[:-len(\".flac\")] for f in flac_files])\n",
    "flac_file_path, txt_file_path = os.path.join(data_dir, f\"{file_id}.flac\"), os.path.join(data_dir, \"2428-83705.trans.txt\")\n",
    "\n",
    "print(\"Text Transcription:\", read_txt_file(txt_file_path)[file_id], \"\\nAudio:\")\n",
    "Audio(filename=flac_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8jJ7Ed81p_A"
   },
   "source": [
    "Now, we will combine all the speech & text samples and will define the function (in next cell) for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:52.844058Z",
     "iopub.status.busy": "2023-05-12T11:57:52.843846Z",
     "iopub.status.idle": "2023-05-12T11:57:52.848838Z",
     "shell.execute_reply": "2023-05-12T11:57:52.848286Z"
    },
    "id": "MI-5YCzaTsei"
   },
   "outputs": [],
   "source": [
    "def fetch_sound_text_mapping(data_dir):\n",
    "  all_files = os.listdir(data_dir)\n",
    "\n",
    "  flac_files = [os.path.join(data_dir, f) for f in all_files if f.endswith(\".flac\")]\n",
    "  txt_files = [os.path.join(data_dir, f) for f in all_files if f.endswith(\".txt\")]\n",
    "\n",
    "  txt_samples = {}\n",
    "  for f in txt_files:\n",
    "    txt_samples.update(read_txt_file(f))\n",
    "\n",
    "  speech_samples = {}\n",
    "  for f in flac_files:\n",
    "    speech_samples.update(read_flac_file(f))\n",
    "\n",
    "  assert len(txt_samples) == len(speech_samples)\n",
    "\n",
    "  samples = [(speech_samples[file_id], txt_samples[file_id]) for file_id in speech_samples.keys() if len(speech_samples[file_id]) < AUDIO_MAXLEN]\n",
    "  return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mx95Lxvu0nT4"
   },
   "source": [
    "It's time to have a look at a few samples ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:52.851765Z",
     "iopub.status.busy": "2023-05-12T11:57:52.851542Z",
     "iopub.status.idle": "2023-05-12T11:57:53.042674Z",
     "shell.execute_reply": "2023-05-12T11:57:53.042138Z"
    },
    "id": "_Ls7X_jqIz4R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.00042725,  0.00061035,  0.00076294, ..., -0.00094604,\n",
       "         -0.00082397, -0.00088501]),\n",
       "  'I GASPED POSITIVELY GASPED'),\n",
       " (array([ 0.00018311,  0.00021362,  0.00021362, ..., -0.00036621,\n",
       "         -0.00036621, -0.00036621]),\n",
       "  'SUCH IS THE SELFISHNESS OF HUMAN NATURE'),\n",
       " (array([-6.10351562e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         -3.96728516e-04, -5.18798828e-04, -3.35693359e-04]),\n",
       "  'AND WHAT INQUIRED MISSUS MACPHERSON HAS MARY ANN GIVEN YOU HER LOVE'),\n",
       " (array([-0.00073242, -0.00054932, -0.00045776, ...,  0.        ,\n",
       "          0.00024414,  0.00042725]),\n",
       "  \"I WAS PERSUADED THAT SOMEBODY BESIDES THAT COUSIN GOT A PROFIT OUT OF MARY ANN'S ENGAGEMENT RING BUT I HANDED OVER THE AMOUNT\"),\n",
       " (array([-9.15527344e-05, -9.15527344e-05, -2.74658203e-04, ...,\n",
       "          3.05175781e-05,  1.22070312e-04,  1.52587891e-04]),\n",
       "  'AS IT IS UNLESS I AM MISTAKEN SOME OF THE RENDING WILL BE ON OUR SIDE AND THEY KNOW IT')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = fetch_sound_text_mapping(data_dir)\n",
    "samples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUjhSWfsnlCL"
   },
   "source": [
    "Note: We are loading this data into memory as we working with a small amount of dataset in this notebook. But for training on the complete dataset (~300 GBs), you will have to load data lazily. You can refer to [this script](https://github.com/vasudevgupta7/gsoc-wav2vec2/blob/main/src/data_utils.py) to know more on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xg8Zia1kzw0J"
   },
   "source": [
    "Let's pre-process the data now !!!\n",
    "\n",
    "We will first define the tokenizer & processor using `gsoc-wav2vec2` package. Then, we will do very simple pre-processing. `processor` will normalize raw speech w.r.to frames axis and `tokenizer` will convert our model outputs into the string (using the defined vocabulary) & will take care of the removal of special tokens (depending on your tokenizer configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:53.045677Z",
     "iopub.status.busy": "2023-05-12T11:57:53.045465Z",
     "iopub.status.idle": "2023-05-12T11:57:53.583452Z",
     "shell.execute_reply": "2023-05-12T11:57:53.582606Z"
    },
    "id": "gaat_hMLNVHF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading `vocab.json` from https://github.com/vasudevgupta7/gsoc-wav2vec2/raw/main/data/vocab.json ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "from wav2vec2 import Wav2Vec2Processor\n",
    "tokenizer = Wav2Vec2Processor(is_tokenizer=True)\n",
    "processor = Wav2Vec2Processor(is_tokenizer=False)\n",
    "\n",
    "def preprocess_text(text):\n",
    "  label = tokenizer(text)\n",
    "  return tf.constant(label, dtype=tf.int32)\n",
    "\n",
    "def preprocess_speech(audio):\n",
    "  audio = tf.constant(audio, dtype=tf.float32)\n",
    "  return processor(tf.transpose(audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyKl8QP-zRFC"
   },
   "source": [
    "Now, we will define the python generator to call the preprocessing functions we defined in above cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:53.587055Z",
     "iopub.status.busy": "2023-05-12T11:57:53.586771Z",
     "iopub.status.idle": "2023-05-12T11:57:53.591020Z",
     "shell.execute_reply": "2023-05-12T11:57:53.590404Z"
    },
    "id": "PoQrRalwMpQ6"
   },
   "outputs": [],
   "source": [
    "def inputs_generator():\n",
    "  for speech, text in samples:\n",
    "    yield preprocess_speech(speech), preprocess_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Vlm3ySFULsG"
   },
   "source": [
    "## Setting up `tf.data.Dataset`\n",
    "\n",
    "Following cell will setup `tf.data.Dataset` object using its `.from_generator(...)` method. We will be using the `generator` object, we defined in the above cell.\n",
    "\n",
    "**Note:** For distributed training (especially on TPUs), `.from_generator(...)` doesn't work currently and it is recommended to train on data stored in `.tfrecord` format (Note: The TFRecords should ideally be stored inside a GCS Bucket in order for the TPUs to work to the fullest extent).\n",
    "\n",
    "You can refer to [this script](https://github.com/vasudevgupta7/gsoc-wav2vec2/blob/main/src/make_tfrecords.py) for more details on how to convert LibriSpeech data into tfrecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:53.593819Z",
     "iopub.status.busy": "2023-05-12T11:57:53.593608Z",
     "iopub.status.idle": "2023-05-12T11:57:53.628252Z",
     "shell.execute_reply": "2023-05-12T11:57:53.627597Z"
    },
    "id": "LbQ_dMwGO62h"
   },
   "outputs": [],
   "source": [
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(None),  dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None), dtype=tf.int32),\n",
    ")\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(inputs_generator, output_signature=output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:53.631176Z",
     "iopub.status.busy": "2023-05-12T11:57:53.630954Z",
     "iopub.status.idle": "2023-05-12T11:57:53.641314Z",
     "shell.execute_reply": "2023-05-12T11:57:53.640747Z"
    },
    "id": "HXBbNsRyPyw3"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(flac_files)\n",
    "SEED = 42\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DAUmns3pXfr"
   },
   "source": [
    "We will pass the dataset into multiple batches, so let's prepare batches in the following cell. Now, all the sequences in a batch should be padded to a constant length. We will use the`.padded_batch(...)` method for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:53.644039Z",
     "iopub.status.busy": "2023-05-12T11:57:53.643828Z",
     "iopub.status.idle": "2023-05-12T11:57:53.653312Z",
     "shell.execute_reply": "2023-05-12T11:57:53.652693Z"
    },
    "id": "Okhko1IWRida"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.padded_batch(BATCH_SIZE, padded_shapes=(AUDIO_MAXLEN, LABEL_MAXLEN), padding_values=(0.0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A45CjQG5qSbV"
   },
   "source": [
    "Accelerators (like GPUs/TPUs) are very fast and often data-loading (& pre-processing) becomes the bottleneck during training as the data-loading part happens on CPUs. This can increase the training time significantly especially when there is a lot of online pre-processing involved or data is streamed online from GCS buckets. To handle those issues, `tf.data.Dataset` offers the `.prefetch(...)` method. This method helps in preparing the next few batches in parallel (on CPUs) while the model is making predictions (on GPUs/TPUs) on the current batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:53.656274Z",
     "iopub.status.busy": "2023-05-12T11:57:53.656021Z",
     "iopub.status.idle": "2023-05-12T11:57:53.660639Z",
     "shell.execute_reply": "2023-05-12T11:57:53.660013Z"
    },
    "id": "f-bKu2YjRior"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqk2cs6LxVIh"
   },
   "source": [
    "Since this notebook is made for demonstration purposes, we will be taking first `num_train_batches` and will perform training over only that. You are encouraged to train on the whole dataset though. Similarly, we will evaluate only `num_val_batches`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:53.663518Z",
     "iopub.status.busy": "2023-05-12T11:57:53.663296Z",
     "iopub.status.idle": "2023-05-12T11:57:53.670768Z",
     "shell.execute_reply": "2023-05-12T11:57:53.670205Z"
    },
    "id": "z6GO5oYUxXtz"
   },
   "outputs": [],
   "source": [
    "num_train_batches = 10\n",
    "num_val_batches = 4\n",
    "\n",
    "train_dataset = dataset.take(num_train_batches)\n",
    "val_dataset = dataset.skip(num_train_batches).take(num_val_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzAOI78tky08"
   },
   "source": [
    "## Model training\n",
    "\n",
    "For training our model, we will be directly calling `.fit(...)` method after compiling our model with `.compile(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:53.673413Z",
     "iopub.status.busy": "2023-05-12T11:57:53.673200Z",
     "iopub.status.idle": "2023-05-12T11:57:53.685326Z",
     "shell.execute_reply": "2023-05-12T11:57:53.684761Z"
    },
    "id": "vuBY2sZElgwg"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qswxafSl0HjO"
   },
   "source": [
    "The above cell will set up our training state. Now we can initiate training with the `.fit(...)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:57:53.688478Z",
     "iopub.status.busy": "2023-05-12T11:57:53.687882Z",
     "iopub.status.idle": "2023-05-12T11:59:17.608911Z",
     "shell.execute_reply": "2023-05-12T11:59:17.608288Z"
    },
    "id": "vtuSfnj1l-I_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/python/ops/ctc_ops.py:1514: alias_inplace_add (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/python/ops/ctc_ops.py:1514: alias_inplace_add (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/python/ops/ctc_ops.py:1497: alias_inplace_update (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/python/ops/ctc_ops.py:1497: alias_inplace_update (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['wav2vec2/masked_spec_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['wav2vec2/masked_spec_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['wav2vec2/masked_spec_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['wav2vec2/masked_spec_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['wav2vec2/masked_spec_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['wav2vec2/masked_spec_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['wav2vec2/masked_spec_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['wav2vec2/masked_spec_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "      1/Unknown - 40s 40s/step - loss: 1886.6428"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      2/Unknown - 41s 1s/step - loss: 1645.2732 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      3/Unknown - 42s 1s/step - loss: 1420.9286"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      4/Unknown - 43s 1s/step - loss: 1251.0692"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      5/Unknown - 45s 1s/step - loss: 1094.7299"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      6/Unknown - 46s 1s/step - loss: 1026.3918"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      7/Unknown - 47s 1s/step - loss: 945.9645 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      8/Unknown - 48s 1s/step - loss: 863.5127"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "      9/Unknown - 49s 1s/step - loss: 835.2319"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "     10/Unknown - 50s 1s/step - loss: 794.8097"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/10 [==============================] - 55s 2s/step - loss: 794.8097 - val_loss: 349.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/10 [==>...........................] - ETA: 10s - loss: 663.4515"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/10 [=====>........................] - ETA: 8s - loss: 612.2675 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3/10 [========>.....................] - ETA: 7s - loss: 525.7752"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4/10 [===========>..................] - ETA: 6s - loss: 489.9207"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/10 [==============>...............] - ETA: 5s - loss: 454.2613"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6/10 [=================>............] - ETA: 4s - loss: 418.4997"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/10 [====================>.........] - ETA: 3s - loss: 408.7490"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8/10 [=======================>......] - ETA: 2s - loss: 391.8790"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9/10 [==========================>...] - ETA: 1s - loss: 386.5086"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/10 [==============================] - ETA: 0s - loss: 379.0593"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/10 [==============================] - 14s 1s/step - loss: 379.0593 - val_loss: 378.2772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/10 [==>...........................] - ETA: 10s - loss: 341.8053"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/10 [=====>........................] - ETA: 8s - loss: 467.3776 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3/10 [========>.....................] - ETA: 7s - loss: 451.1385"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4/10 [===========>..................] - ETA: 6s - loss: 455.4031"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/10 [==============>...............] - ETA: 5s - loss: 406.7318"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6/10 [=================>............] - ETA: 4s - loss: 400.7153"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 7/10 [====================>.........] - ETA: 3s - loss: 385.4377"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8/10 [=======================>......] - ETA: 2s - loss: 377.7065"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9/10 [==========================>...] - ETA: 1s - loss: 409.7403"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/10 [==============================] - ETA: 0s - loss: 412.3554"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/10 [==============================] - 14s 1s/step - loss: 412.3554 - val_loss: 519.3557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [794.8096923828125, 379.05926513671875, 412.35540771484375],\n",
       " 'val_loss': [349.9258728027344, 378.27716064453125, 519.3556518554688]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=3)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySvp8r2E1q_V"
   },
   "source": [
    "Let's save our model with `.save(...)` method to be able to perform inference later. You can also export this SavedModel to TFHub by following [TFHub documentation](https://www.tensorflow.org/hub/publish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:59:17.612274Z",
     "iopub.status.busy": "2023-05-12T11:59:17.612031Z",
     "iopub.status.idle": "2023-05-12T11:59:25.079626Z",
     "shell.execute_reply": "2023-05-12T11:59:25.078936Z"
    },
    "id": "C0KEYcwydwjF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finetuned-wav2vec2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finetuned-wav2vec2/assets\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"finetuned-wav2vec2\"\n",
    "model.save(save_dir, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkOpp9rZ211t"
   },
   "source": [
    "Note: We are setting `include_optimizer=False` as we want to use this model for inference only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJfPlTgezD0i"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Now we will be computing Word Error Rate over the validation dataset\n",
    "\n",
    "**Word error rate** (WER) is a common metric for measuring the performance of an automatic speech recognition system. The WER is derived from the Levenshtein distance, working at the word level. Word error rate can then be computed as: WER = (S + D + I) / N = (S + D + I) / (S + D + C) where S is the number of substitutions, D is the number of deletions, I is the number of insertions, C is the number of correct words, N is the number of words in the reference (N=S+D+C). This value indicates the percentage of words that were incorrectly predicted. \n",
    "\n",
    "You can refer to [this paper](https://www.isca-speech.org/archive_v0/interspeech_2004/i04_2765.html) to learn more about WER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Io_91Y7-r3xu"
   },
   "source": [
    "We will use `load_metric(...)` function from [HuggingFace datasets](https://huggingface.co/docs/datasets/) library. Let's first install the `datasets` library using `pip` and then define the `metric` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:59:25.083656Z",
     "iopub.status.busy": "2023-05-12T11:59:25.083417Z",
     "iopub.status.idle": "2023-05-12T11:59:32.060766Z",
     "shell.execute_reply": "2023-05-12T11:59:32.060126Z"
    },
    "id": "GW9F_oVDU1TZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmpfs/tmp/ipykernel_24583/1786190190.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"wer\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5485b8c6cd884d998b6302da820bd888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip3 install -q datasets\n",
    "\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:59:32.064442Z",
     "iopub.status.busy": "2023-05-12T11:59:32.064010Z",
     "iopub.status.idle": "2023-05-12T11:59:32.069143Z",
     "shell.execute_reply": "2023-05-12T11:59:32.068609Z"
    },
    "id": "ssWXWc7CZvNB"
   },
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)\n",
    "def eval_fwd(batch):\n",
    "  logits = model(batch, training=False)\n",
    "  return tf.argmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFh1myg1x4ua"
   },
   "source": [
    "It's time to run the evaluation on validation data now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:59:32.072089Z",
     "iopub.status.busy": "2023-05-12T11:59:32.071883Z",
     "iopub.status.idle": "2023-05-12T11:59:37.782808Z",
     "shell.execute_reply": "2023-05-12T11:59:37.782091Z"
    },
    "id": "EQTFVjZghckJ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272892db640146c8bc5bec71307e3161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 11:59:32.651407: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. model/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/wav2vec2/encoder/layers/0/stochastic_depth/random_uniform/RandomUniform\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for speech, labels in tqdm(val_dataset, total=num_val_batches):\n",
    "    predictions  = eval_fwd(speech)\n",
    "    predictions = [tokenizer.decode(pred) for pred in predictions.numpy().tolist()]\n",
    "    references = [tokenizer.decode(label, group_tokens=False) for label in labels.numpy().tolist()]\n",
    "    metric.add_batch(references=references, predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWCc8qBesv3e"
   },
   "source": [
    "We are using the `tokenizer.decode(...)` method for decoding our predictions and labels back into the text and will add them to the metric for `WER` computation later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI_URj8Wtb2g"
   },
   "source": [
    "Now, let's calculate the metric value in following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:59:37.787400Z",
     "iopub.status.busy": "2023-05-12T11:59:37.786758Z",
     "iopub.status.idle": "2023-05-12T11:59:37.794754Z",
     "shell.execute_reply": "2023-05-12T11:59:37.794131Z"
    },
    "id": "a83wekLgWMod"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_cD1OgVEjl4"
   },
   "source": [
    "**Note:** Here metric value doesn't make any sense as the model is trained on very small data and ASR-like tasks often require a large amount of data to learn a mapping from speech to text. You should probably train on large data to get some good results. This notebook gives you a template to fine-tune a pre-trained speech model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G14o706kdTE1"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Now that we are satisfied with the training process & have saved the model in `save_dir`, we will see how this model can be used for inference.\n",
    "\n",
    "First, we will load our model using `tf.keras.models.load_model(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:59:37.798329Z",
     "iopub.status.busy": "2023-05-12T11:59:37.797745Z",
     "iopub.status.idle": "2023-05-12T11:59:45.167556Z",
     "shell.execute_reply": "2023-05-12T11:59:45.166808Z"
    },
    "id": "wrTrExiUdaED"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = tf.keras.models.load_model(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luodSroz20SR"
   },
   "source": [
    "Let's download some speech samples for performing inference. You can replace the following sample with your speech sample also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:59:45.171113Z",
     "iopub.status.busy": "2023-05-12T11:59:45.170591Z",
     "iopub.status.idle": "2023-05-12T11:59:45.854975Z",
     "shell.execute_reply": "2023-05-12T11:59:45.854057Z"
    },
    "id": "HUE0shded6Ej"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-12 11:59:45--  https://github.com/vasudevgupta7/gsoc-wav2vec2/raw/main/data/SA2.wav\r\n",
      "Resolving github.com (github.com)... 192.30.255.112\r\n",
      "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\r\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 Moved Permanently\r\n",
      "Location: https://github.com/thevasudevgupta/gsoc-wav2vec2/raw/main/data/SA2.wav [following]\r\n",
      "--2023-05-12 11:59:45--  https://github.com/thevasudevgupta/gsoc-wav2vec2/raw/main/data/SA2.wav\r\n",
      "Reusing existing connection to github.com:443.\r\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 Found\r\n",
      "Location: https://raw.githubusercontent.com/thevasudevgupta/gsoc-wav2vec2/main/data/SA2.wav [following]\r\n",
      "--2023-05-12 11:59:45--  https://raw.githubusercontent.com/thevasudevgupta/gsoc-wav2vec2/main/data/SA2.wav\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\r\n",
      "Length: 94252 (92K) [audio/wav]\r\n",
      "Saving to: ‘SA2.wav’\r\n",
      "\r\n",
      "\r",
      "SA2.wav               0%[                    ]       0  --.-KB/s               \r",
      "SA2.wav             100%[===================>]  92.04K  --.-KB/s    in 0.008s  \r\n",
      "\r\n",
      "2023-05-12 11:59:45 (10.9 MB/s) - ‘SA2.wav’ saved [94252/94252]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/vasudevgupta7/gsoc-wav2vec2/raw/main/data/SA2.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycBjU_U53FjL"
   },
   "source": [
    "Now, we will read the speech sample using `soundfile.read(...)` and pad it to `AUDIO_MAXLEN` to satisfy the model signature. Then we will normalize that speech sample using the `Wav2Vec2Processor` instance & will feed it into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:59:45.858741Z",
     "iopub.status.busy": "2023-05-12T11:59:45.858456Z",
     "iopub.status.idle": "2023-05-12T11:59:46.986739Z",
     "shell.execute_reply": "2023-05-12T11:59:46.986076Z"
    },
    "id": "z7CARje4d5_H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 768, 32), dtype=float32, numpy=\n",
       "array([[[ 0.11623144, -0.6569348 , -0.62540257, ..., -0.78131443,\n",
       "         -0.7557185 , -0.83161324],\n",
       "        [ 0.11701638, -0.66613764, -0.6340393 , ..., -0.77830833,\n",
       "         -0.76579994, -0.8261736 ],\n",
       "        [ 0.14664587, -0.6441441 , -0.6355415 , ..., -0.7737473 ,\n",
       "         -0.7887615 , -0.8338203 ],\n",
       "        ...,\n",
       "        [-0.00312984, -0.89380676, -0.5470859 , ..., -0.582591  ,\n",
       "         -0.94601464, -0.93357545],\n",
       "        [-0.00409425, -0.894342  , -0.5474911 , ..., -0.5832409 ,\n",
       "         -0.94700104, -0.9324878 ],\n",
       "        [-0.00999692, -0.89833087, -0.5418743 , ..., -0.57743007,\n",
       "         -0.95411545, -0.93438494]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "speech, _ = sf.read(\"SA2.wav\")\n",
    "speech = np.pad(speech, (0, AUDIO_MAXLEN - len(speech)))\n",
    "speech = tf.expand_dims(processor(tf.constant(speech)), 0)\n",
    "\n",
    "outputs = finetuned_model(speech)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUSttSPa30qP"
   },
   "source": [
    "Let's decode numbers back into text sequence using the `Wav2Vec2tokenizer` instance, we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T11:59:46.990194Z",
     "iopub.status.busy": "2023-05-12T11:59:46.989693Z",
     "iopub.status.idle": "2023-05-12T11:59:46.996118Z",
     "shell.execute_reply": "2023-05-12T11:59:46.995549Z"
    },
    "id": "RYdJqxQ4llgI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(outputs, axis=-1)\n",
    "predictions = [tokenizer.decode(pred) for pred in predictions.numpy().tolist()]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DXC757bztJc"
   },
   "source": [
    "This prediction is quite random as the model was never trained on large data in this notebook (as this notebook is not meant for doing complete training). You will get good predictions if you train this model on complete LibriSpeech dataset.\n",
    "\n",
    "Finally, we have reached an end to this notebook. But it's not an end of learning TensorFlow for speech-related tasks, this [repository](https://github.com/tulasiram58827/TTS_TFLite) contains some more amazing tutorials. In case you encountered any bug in this notebook, please create an issue [here](https://github.com/vasudevgupta7/gsoc-wav2vec2/issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBEm6caxYDyK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "rWk8nL6Ui-_0",
    "wvuJL8-f0zn5",
    "oPp18ZHRtnq-",
    "1mvTuOXpwsQe",
    "7Vlm3ySFULsG",
    "CzAOI78tky08",
    "SJfPlTgezD0i",
    "G14o706kdTE1"
   ],
   "name": "wav2vec2-saved-model-finetuning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "184c0bf4d405d4a36e719b504ff2a22c838d19108535bf816dff1a5aad495b87"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('t5': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0560046359594971b8018e4788fe2d67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19f1146c169348efae5413a0574f8d7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "21299a10598d474e96695cd6e9617a48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "247302164f6a4425b5398d6346af6cad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "272892db640146c8bc5bec71307e3161": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2ac512a30b9040dcab54db7d20167712",
        "IPY_MODEL_4abcdfc691dc48c99eb82998932d6b81",
        "IPY_MODEL_befc136fd68a4f36b84161a37f526b1e"
       ],
       "layout": "IPY_MODEL_8b8d0921bd5f44dea1ebfa33510a59ca",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2ac512a30b9040dcab54db7d20167712": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_461b5059767e41c694e7f4a12c106730",
       "placeholder": "​",
       "style": "IPY_MODEL_247302164f6a4425b5398d6346af6cad",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "3217721c2956476fb4804a062aec716d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "355d50f7e5124f039bb898cfed7974c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "461b5059767e41c694e7f4a12c106730": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4abcdfc691dc48c99eb82998932d6b81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3217721c2956476fb4804a062aec716d",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bcbf3ac8d7884ae39aa7e655c44792d6",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     },
     "5485b8c6cd884d998b6302da820bd888": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9812066b5d6a42ea9aad7a7a9075a2f8",
        "IPY_MODEL_7b02ce5dcd404e3791c2f557853b08c5",
        "IPY_MODEL_c9b8b7c3dcfd4e008225252f71b3382e"
       ],
       "layout": "IPY_MODEL_0560046359594971b8018e4788fe2d67",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7b02ce5dcd404e3791c2f557853b08c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e57e6b8339df4b2aa847bd0869af72eb",
       "max": 1901.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_21299a10598d474e96695cd6e9617a48",
       "tabbable": null,
       "tooltip": null,
       "value": 1901.0
      }
     },
     "8b8d0921bd5f44dea1ebfa33510a59ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9812066b5d6a42ea9aad7a7a9075a2f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_355d50f7e5124f039bb898cfed7974c3",
       "placeholder": "​",
       "style": "IPY_MODEL_d0b20dd18d454710bf3b3a5acfda8b66",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading builder script: "
      }
     },
     "a7301e0679174b719ce0d3540c85add5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2a0ab988cda47c3aadb51c4de2d90e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bcbf3ac8d7884ae39aa7e655c44792d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "befc136fd68a4f36b84161a37f526b1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b2a0ab988cda47c3aadb51c4de2d90e5",
       "placeholder": "​",
       "style": "IPY_MODEL_f35fbdda43ef4821b5d34f53f0ff87bf",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [00:05&lt;00:00,  1.48s/it]"
      }
     },
     "c9b8b7c3dcfd4e008225252f71b3382e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a7301e0679174b719ce0d3540c85add5",
       "placeholder": "​",
       "style": "IPY_MODEL_19f1146c169348efae5413a0574f8d7c",
       "tabbable": null,
       "tooltip": null,
       "value": " 4.48k/? [00:00&lt;00:00, 551kB/s]"
      }
     },
     "d0b20dd18d454710bf3b3a5acfda8b66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e57e6b8339df4b2aa847bd0869af72eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f35fbdda43ef4821b5d34f53f0ff87bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
